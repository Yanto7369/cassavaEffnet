{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:29:44.750955Z",
     "iopub.status.busy": "2021-01-25T02:29:44.750004Z",
     "iopub.status.idle": "2021-01-25T02:29:57.558430Z",
     "shell.execute_reply": "2021-01-25T02:29:57.557660Z"
    },
    "papermill": {
     "duration": 12.840779,
     "end_time": "2021-01-25T02:29:57.558589",
     "exception": false,
     "start_time": "2021-01-25T02:29:44.717810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.2.0\n",
      "Device: grpc://10.0.0.2:8470\n",
      "Number of replicas: 8\n"
     ]
    }
   ],
   "source": [
    "import math, re, os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "from tensorflow import keras\n",
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Device:', tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "print('Number of replicas:', strategy.num_replicas_in_sync)\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "GCS_PATH = KaggleDatasets().get_gcs_path()\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "IMAGE_SIZE = [512, 512]\n",
    "CLASSES = ['0', '1', '2', '3', '4']\n",
    "EPOCHS = 10\n",
    "def decode_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
    "    return image\n",
    "def read_tfrecord(example, labeled):\n",
    "    tfrecord_format = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64)\n",
    "    } if labeled else {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
    "    image = decode_image(example['image'])\n",
    "    if labeled:\n",
    "        label = tf.cast(example['target'], tf.int32)\n",
    "        return image, label\n",
    "    idnum = example['image_name']\n",
    "    return image, idnum\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE)\n",
    "    return dataset\n",
    "TRAINING_FILENAMES, VALID_FILENAMES = train_test_split(\n",
    "    tf.io.gfile.glob(GCS_PATH + '/train_tfrecords/ld_train*.tfrec'),\n",
    "    test_size=0.35, random_state=5\n",
    ")\n",
    "def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n",
    "    # returns 3x3 transformmatrix which transforms indicies\n",
    "        \n",
    "    # CONVERT DEGREES TO RADIANS\n",
    "    rotation = math.pi * rotation / 180.\n",
    "    shear = math.pi * shear / 180.\n",
    "    \n",
    "    # ROTATION MATRIX\n",
    "    c1 = tf.math.cos(rotation)\n",
    "    s1 = tf.math.sin(rotation)\n",
    "    one = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    rotation_matrix = tf.reshape( tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3] )\n",
    "        \n",
    "    # SHEAR MATRIX\n",
    "    c2 = tf.math.cos(shear)\n",
    "    s2 = tf.math.sin(shear)\n",
    "    shear_matrix = tf.reshape( tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3] )    \n",
    "    \n",
    "    # ZOOM MATRIX\n",
    "    zoom_matrix = tf.reshape( tf.concat([one/height_zoom,zero,zero, zero,one/width_zoom,zero, zero,zero,one],axis=0),[3,3] )\n",
    "    \n",
    "    # SHIFT MATRIX\n",
    "    shift_matrix = tf.reshape( tf.concat([one,zero,height_shift, zero,one,width_shift, zero,zero,one],axis=0),[3,3] )\n",
    "    \n",
    "    return K.dot(K.dot(rotation_matrix, shear_matrix), K.dot(zoom_matrix, shift_matrix))\n",
    "def transform(image,label):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly rotated, sheared, zoomed, and shifted\n",
    "    DIM = IMAGE_SIZE[0]\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "    \n",
    "    rot = 15. * tf.random.normal([1],dtype='float32')\n",
    "    shr = 5. * tf.random.normal([1],dtype='float32') \n",
    "    h_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10.\n",
    "    w_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10.\n",
    "    h_shift = 16. * tf.random.normal([1],dtype='float32') \n",
    "    w_shift = 16. * tf.random.normal([1],dtype='float32') \n",
    "  \n",
    "    # GET TRANSFORMATION MATRIX\n",
    "    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
    "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
    "    z = tf.ones([DIM*DIM],dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(m,tf.cast(idx,dtype='float32'))\n",
    "    idx2 = K.cast(idx2,dtype='int32')\n",
    "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES           \n",
    "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
    "    d = tf.gather_nd(image,tf.transpose(idx3))\n",
    "        \n",
    "    return tf.reshape(d,[DIM,DIM,3]),label\n",
    "TEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/test_tfrecords/ld_test*.tfrec')\n",
    "def data_augment(image, label):\n",
    "    # Thanks to the dataset.prefetch(AUTO) statement in the following function this happens essentially for free on TPU. \n",
    "    # Data pipeline code is executed on the \"CPU\" part of the TPU while the TPU itself is computing gradients.\n",
    "    #image = tf.image.random_flip_left_right(image)\n",
    "    return transform(image,label)#image, label\n",
    "def get_test_dataset(ordered=False):\n",
    "    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset\n",
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:29:57.620256Z",
     "iopub.status.busy": "2021-01-25T02:29:57.619553Z",
     "iopub.status.idle": "2021-01-25T02:30:01.839276Z",
     "shell.execute_reply": "2021-01-25T02:30:01.838412Z"
    },
    "papermill": {
     "duration": 4.252355,
     "end_time": "2021-01-25T02:30:01.839446",
     "exception": false,
     "start_time": "2021-01-25T02:29:57.587091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet\r\n",
      "  Cloning https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet to /tmp/pip-req-build-q13idzcw\r\n",
      "  Running command git clone -q https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet /tmp/pip-req-build-q13idzcw\r\n",
      "  fatal: repository 'https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet/' not found\r\n",
      "\u001b[31mERROR: Command errored out with exit status 128: git clone -q https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet /tmp/pip-req-build-q13idzcw Check the logs for full command output.\u001b[0m\r\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.0 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U git+https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:30:01.913861Z",
     "iopub.status.busy": "2021-01-25T02:30:01.907082Z",
     "iopub.status.idle": "2021-01-25T02:30:13.716962Z",
     "shell.execute_reply": "2021-01-25T02:30:13.716211Z"
    },
    "papermill": {
     "duration": 11.848088,
     "end_time": "2021-01-25T02:30:13.717091",
     "exception": false,
     "start_time": "2021-01-25T02:30:01.869003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/qubvel/efficientnet\r\n",
      "  Cloning https://github.com/qubvel/efficientnet to /tmp/pip-req-build-8yxmqt3f\r\n",
      "  Running command git clone -q https://github.com/qubvel/efficientnet /tmp/pip-req-build-8yxmqt3f\r\n",
      "Collecting keras_applications<=1.0.8,>=1.0.7\r\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 50 kB 1.4 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.1.1) (0.16.2)\r\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.1) (1.18.5)\r\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/lib/python3.7/site-packages (from keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.1) (2.10.0)\r\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.1) (1.4.1)\r\n",
      "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.1) (3.2.1)\r\n",
      "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.1) (2.4)\r\n",
      "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.1) (7.2.0)\r\n",
      "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.1) (2.8.0)\r\n",
      "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.1) (1.1.1)\r\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.1) (1.14.0)\r\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.1) (2.8.1)\r\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.1) (0.10.0)\r\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.1) (2.4.7)\r\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.1) (1.2.0)\r\n",
      "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.1.1) (4.4.2)\r\n",
      "Building wheels for collected packages: efficientnet\r\n",
      "  Building wheel for efficientnet (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for efficientnet: filename=efficientnet-1.1.1-py3-none-any.whl size=18420 sha256=7c460024b64e85cd4374f0621f7a6bfa7e90a79ba82cb27156ee70e2216821aa\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-0sem7pse/wheels/11/69/85/814d64d694c96db0eef17b718042d644a1e54f113920481920\r\n",
      "Successfully built efficientnet\r\n",
      "Installing collected packages: keras-applications, efficientnet\r\n",
      "Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\r\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.0 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U git+https://github.com/qubvel/efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:30:13.798476Z",
     "iopub.status.busy": "2021-01-25T02:30:13.797709Z",
     "iopub.status.idle": "2021-01-25T02:30:21.014577Z",
     "shell.execute_reply": "2021-01-25T02:30:21.013683Z"
    },
    "papermill": {
     "duration": 7.260897,
     "end_time": "2021-01-25T02:30:21.014740",
     "exception": false,
     "start_time": "2021-01-25T02:30:13.753843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: efficientnet in /opt/conda/lib/python3.7/site-packages (1.1.1)\r\n",
      "Requirement already satisfied, skipping upgrade: keras-applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.7/site-packages (from efficientnet) (1.0.8)\r\n",
      "Requirement already satisfied, skipping upgrade: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet) (0.16.2)\r\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.18.5)\r\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.10.0)\r\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (1.4.1)\r\n",
      "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (3.2.1)\r\n",
      "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (2.4)\r\n",
      "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (7.2.0)\r\n",
      "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (2.8.0)\r\n",
      "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (1.1.1)\r\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.14.0)\r\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.2.0)\r\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\r\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.7)\r\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.1)\r\n",
      "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.2)\r\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.0 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:30:21.102715Z",
     "iopub.status.busy": "2021-01-25T02:30:21.101949Z",
     "iopub.status.idle": "2021-01-25T02:30:21.489805Z",
     "shell.execute_reply": "2021-01-25T02:30:21.489123Z"
    },
    "papermill": {
     "duration": 0.438432,
     "end_time": "2021-01-25T02:30:21.489947",
     "exception": false,
     "start_time": "2021-01-25T02:30:21.051515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import efficientnet.keras as efn \n",
    "from efficientnet.keras import EfficientNetB5\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from keras.models import Model\n",
    "#from adam_lr_mult import Adam_lr_mult\n",
    "\n",
    "def prepare_new_model(input_shape, class_count):\n",
    "    # 学習済みモデルの取り出し\n",
    "    feature_extractor = EfficientNetB5(input_shape=input_shape, weights='imagenet', include_top=False)\n",
    "    # 犬猫分類器を引っ付ける\n",
    "    x = feature_extractor.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(rate=0.25)(x)\n",
    "    x = Dense(len(CLASSES), activation='softmax')(x)\n",
    "    # 新たなモデルの定義\n",
    "    model = Model(inputs=feature_extractor.input, outputs=x)\n",
    "    #print(model.summary())\n",
    "    return model\n",
    "\n",
    "def get_adam_for_fine_tuning(lr, decay, multiplier, model):\n",
    "    lr_multiplier = {}\n",
    "    # 自分が引っ付けたレイヤーの学習係数は1、学習済みの部分は小さな値を設定する\n",
    "    for layer in model.layers:\n",
    "        if 'dense' in layer.name:\n",
    "            lr_multiplier[layer.name] = 1.0\n",
    "        else:\n",
    "            lr_multiplier[layer.name] = multiplier\n",
    "    return Adam_lr_mult(lr=lr, decay=decay, multipliers=lr_multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:30:21.574521Z",
     "iopub.status.busy": "2021-01-25T02:30:21.567403Z",
     "iopub.status.idle": "2021-01-25T02:30:22.305626Z",
     "shell.execute_reply": "2021-01-25T02:30:22.304957Z"
    },
    "papermill": {
     "duration": 0.779673,
     "end_time": "2021-01-25T02:30:22.305746",
     "exception": false,
     "start_time": "2021-01-25T02:30:21.526073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:30:22.386603Z",
     "iopub.status.busy": "2021-01-25T02:30:22.385405Z",
     "iopub.status.idle": "2021-01-25T02:30:23.228598Z",
     "shell.execute_reply": "2021-01-25T02:30:23.227980Z"
    },
    "papermill": {
     "duration": 0.88663,
     "end_time": "2021-01-25T02:30:23.228730",
     "exception": false,
     "start_time": "2021-01-25T02:30:22.342100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-01-25 02:30:23--  http://./EffNetB0_456_8_best_weights.h5\r\n",
      "Resolving . (.)... failed: No address associated with hostname.\r\n",
      "wget: unable to resolve host address ‘.’\r\n"
     ]
    }
   ],
   "source": [
    "!wget ./EffNetB0_456_8_best_weights.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:30:23.314387Z",
     "iopub.status.busy": "2021-01-25T02:30:23.313368Z",
     "iopub.status.idle": "2021-01-25T02:31:10.517551Z",
     "shell.execute_reply": "2021-01-25T02:31:10.516258Z"
    },
    "papermill": {
     "duration": 47.252574,
     "end_time": "2021-01-25T02:31:10.517702",
     "exception": false,
     "start_time": "2021-01-25T02:30:23.265128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b5_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
      "115515392/115515256 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import math, re, os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from functools import partial\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
    "\n",
    "with  strategy.scope():   \n",
    "    input_shape=[456,456,3]\n",
    "    model = prepare_new_model(input_shape, len(CLASSES))\n",
    "    # ファインチューニング用Adamオプティマイザ\n",
    "    #optimizer = get_adam_for_fine_tuning(lr=1e-3, decay=1e-5, multiplier=0.01, model=model)\n",
    "    # コンパイルして\n",
    "    model.compile(tf.keras.optimizers.Adam(lr = 0.001,decay=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:10.627895Z",
     "iopub.status.busy": "2021-01-25T02:31:10.625050Z",
     "iopub.status.idle": "2021-01-25T02:31:10.631307Z",
     "shell.execute_reply": "2021-01-25T02:31:10.631801Z"
    },
    "papermill": {
     "duration": 0.063576,
     "end_time": "2021-01-25T02:31:10.631955",
     "exception": false,
     "start_time": "2021-01-25T02:31:10.568379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "repeat=2\n",
    "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)*repeat\n",
    "NUM_VALIDATION_IMAGES = count_data_items(VALID_FILENAMES)\n",
    "NUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n",
    "def get_training_dataset(batchsize=BATCH_SIZE):\n",
    "    dataset = load_dataset(TRAINING_FILENAMES, labeled=True) \n",
    "    dataset = dataset.repeat(repeat)\n",
    "    dataset = dataset.map(data_augment, num_parallel_calls=AUTOTUNE)  \n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(batchsize)\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset\n",
    "def get_validation_dataset(ordered=False,batchsize=BATCH_SIZE):\n",
    "    dataset = load_dataset(VALID_FILENAMES, labeled=True, ordered=ordered) \n",
    "    #dataset = dataset.map(data_augment, num_parallel_calls=AUTOTUNE) \n",
    "    dataset = dataset.batch(batchsize)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:10.742044Z",
     "iopub.status.busy": "2021-01-25T02:31:10.741128Z",
     "iopub.status.idle": "2021-01-25T02:31:12.484956Z",
     "shell.execute_reply": "2021-01-25T02:31:12.485855Z"
    },
    "papermill": {
     "duration": 1.80597,
     "end_time": "2021-01-25T02:31:12.486061",
     "exception": false,
     "start_time": "2021-01-25T02:31:10.680091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_save' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5d4b484643f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mfine_tune_at\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfine_tune_at\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-5d4b484643f4>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(epoch, bs)\u001b[0m\n\u001b[1;32m     12\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVALID_STEPS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                         )\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#base_model.trainable=True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_save' is not defined"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "bs=BATCH_SIZE\n",
    "train_dataset = get_training_dataset(batchsize=bs)\n",
    "valid_dataset = get_validation_dataset(batchsize=bs)\n",
    "def learn(epoch,bs):\n",
    "    EPOCHS = epoch\n",
    "    STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // bs\n",
    "    VALID_STEPS = NUM_VALIDATION_IMAGES // bs\n",
    "    history = model.fit(train_dataset, \n",
    "                        steps_per_epoch=STEPS_PER_EPOCH, \n",
    "                        epochs=EPOCHS,\n",
    "                        validation_data=valid_dataset,\n",
    "                        validation_steps=VALID_STEPS,\n",
    "                        callbacks=[model_save, early_stop]\n",
    "                        )\n",
    "#base_model.trainable=True\n",
    "\n",
    "\n",
    "learn(5,BATCH_SIZE)\n",
    "fine_tune_at = 500\n",
    "for layer in model.layers[:fine_tune_at]:\n",
    "    layer.trainable =  False\n",
    "learn(30,BATCH_SIZE)\n",
    "#radam.min_lr=4e-4\n",
    "#fine_tune_at = 200\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "#\"for layer in base_model.layers[:fine_tune_at]:\n",
    "#\"\"    layer.trainable =  False\n",
    "#BATCH_SIZE = 4 * strategy.num_replicas_in_sync\n",
    "#learn(10,BATCH_SIZE)\n",
    "#BATCH_SIZE = 1 * strategy.num_replicas_in_sync\n",
    "#learn(5,BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:12.592440Z",
     "iopub.status.busy": "2021-01-25T02:31:12.591756Z",
     "iopub.status.idle": "2021-01-25T02:31:12.658469Z",
     "shell.execute_reply": "2021-01-25T02:31:12.659092Z"
    },
    "papermill": {
     "duration": 0.118844,
     "end_time": "2021-01-25T02:31:12.659263",
     "exception": false,
     "start_time": "2021-01-25T02:31:12.540419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_save' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5ae3138d51e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfine_tune_at\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-5d4b484643f4>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(epoch, bs)\u001b[0m\n\u001b[1;32m     12\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVALID_STEPS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                         )\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#base_model.trainable=True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_save' is not defined"
     ]
    }
   ],
   "source": [
    "fine_tune_at = 400\n",
    "for layer in model.layers[:fine_tune_at]:\n",
    "    layer.trainable =  False\n",
    "learn(30,BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:12.759760Z",
     "iopub.status.busy": "2021-01-25T02:31:12.758977Z",
     "iopub.status.idle": "2021-01-25T02:31:12.823556Z",
     "shell.execute_reply": "2021-01-25T02:31:12.822820Z"
    },
    "papermill": {
     "duration": 0.115773,
     "end_time": "2021-01-25T02:31:12.823684",
     "exception": false,
     "start_time": "2021-01-25T02:31:12.707911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_save' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5ae3138d51e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfine_tune_at\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-5d4b484643f4>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(epoch, bs)\u001b[0m\n\u001b[1;32m     12\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVALID_STEPS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                         )\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#base_model.trainable=True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_save' is not defined"
     ]
    }
   ],
   "source": [
    "fine_tune_at = 400\n",
    "for layer in model.layers[:fine_tune_at]:\n",
    "    layer.trainable =  False\n",
    "learn(30,BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:12.934852Z",
     "iopub.status.busy": "2021-01-25T02:31:12.933873Z",
     "iopub.status.idle": "2021-01-25T02:31:12.938175Z",
     "shell.execute_reply": "2021-01-25T02:31:12.937483Z"
    },
    "papermill": {
     "duration": 0.064848,
     "end_time": "2021-01-25T02:31:12.938299",
     "exception": false,
     "start_time": "2021-01-25T02:31:12.873451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "model_save = ModelCheckpoint('./EffNetB0_456_8_best_weights.h5', \n",
    "                             save_best_only = True, \n",
    "                             save_weights_only = False,\n",
    "                             monitor = 'val_loss', \n",
    "                             mode = 'min', verbose = 1)\n",
    "early_stop = EarlyStopping(monitor = 'val_loss', min_delta = 0.001, \n",
    "                           patience = 3, mode = 'min', verbose = 1,\n",
    "                           restore_best_weights = True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.3, \n",
    "                              patience = 10, min_delta = 0.001, \n",
    "                              mode = 'min', verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:13.041812Z",
     "iopub.status.busy": "2021-01-25T02:31:13.041027Z",
     "iopub.status.idle": "2021-01-25T02:31:13.081933Z",
     "shell.execute_reply": "2021-01-25T02:31:13.082653Z"
    },
    "papermill": {
     "duration": 0.093539,
     "end_time": "2021-01-25T02:31:13.082820",
     "exception": false,
     "start_time": "2021-01-25T02:31:12.989281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'class_count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-292e2f51447d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     decay_rate=0.9)\n\u001b[1;32m     14\u001b[0m \u001b[0;32mwith\u001b[0m  \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_new_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m# ファインチューニング用Adamオプティマイザ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_adam_for_fine_tuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'class_count' is not defined"
     ]
    }
   ],
   "source": [
    "import math, re, os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from functools import partial\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
    "# loading pretrained conv base model\n",
    "lr_scheduler = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-1, \n",
    "    decay_steps=10, \n",
    "    decay_rate=0.9)\n",
    "with  strategy.scope():   \n",
    "    model = prepare_new_model(input_shape, class_count)\n",
    "    # ファインチューニング用Adamオプティマイザ\n",
    "    optimizer = get_adam_for_fine_tuning(lr=1e-3, decay=1e-5, multiplier=0.01, model=model)\n",
    "    # コンパイルして\n",
    "    model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    #EfficientNetB0\n",
    "    #RESIZE=[456,456]\n",
    "    #img_adjust_layer = tf.keras.layers.Lambda(preprocess_input, input_shape=[*RESIZE, 3])\n",
    "    #adjust=tf.keras.backend.expand_dims(x, axis=0),\n",
    "    #x = center_crop_and_resize(image, image_size=image_size)\n",
    "    #base_model.trainable=False\n",
    "    input_shape=(512,512,3)\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x=BatchNormalization()(inputs)\n",
    "    #x=Conv2D(32,(2,2),activation=keras.activations.relu)(inputs)\n",
    "    #x=Conv2D(16,(2,2),activation=keras.activations.relu)(inputs)\n",
    "    #x=Conv2D(16,(256,256),activation=keras.activations.relu)(x)\n",
    "    former=3\n",
    "    channnel,size,loop=[32,16,24,40,80,112,192,320],[3,3,3,5,3,5,5,3],[1,1,2,2,3,3,4,1]\n",
    "    for i in range(0,len(channnel)):\n",
    "        for i in range(loop[i]):\n",
    "            x=Conv2D(channnel[i]*former,(size[i],size[i]),padding=\"same\",activation=keras.activations.relu)(x)\n",
    "            former=size[i]\n",
    "        x=MaxPooling2D(pool_size=(2, 2))(x)\n",
    "            \n",
    "    x=GlobalAveragePooling2D()(x)\n",
    "    x=Dense(len(CLASSES), activation='softmax')(x)\n",
    "    model=tf.keras.models.Model(inputs=inputs, outputs=x)\n",
    "    #radam = tfa.optimizers.Rectifi\n",
    "    # edAdam(min_lr=0.017,)\n",
    "    #ranger = tfa.optimizers.Lookahead(radam, sync_period=6, slow_step_size=0.5)\n",
    "    #for i in range(4):\n",
    "    #    model.add( tf.keras.layers.Dense(8, activation='relu'))\n",
    "    #model.add(tf.keras.layers.Dense(len(CLASSES), activation='softmax'))\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(lr = 0.001),\n",
    "        loss='sparse_categorical_crossentropy',  \n",
    "        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:13.189124Z",
     "iopub.status.busy": "2021-01-25T02:31:13.188253Z",
     "iopub.status.idle": "2021-01-25T02:31:13.199704Z",
     "shell.execute_reply": "2021-01-25T02:31:13.200560Z"
    },
    "papermill": {
     "duration": 0.068099,
     "end_time": "2021-01-25T02:31:13.200771",
     "exception": false,
     "start_time": "2021-01-25T02:31:13.132672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573\n",
      "382.0\n"
     ]
    }
   ],
   "source": [
    "lay=0\n",
    "for layer in model.layers:\n",
    "    lay+=1\n",
    "print(lay)\n",
    "print(lay*2/3)\n",
    "#print(base_model.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:13.318479Z",
     "iopub.status.busy": "2021-01-25T02:31:13.317432Z",
     "iopub.status.idle": "2021-01-25T02:31:13.531298Z",
     "shell.execute_reply": "2021-01-25T02:31:13.532245Z"
    },
    "papermill": {
     "duration": 0.274653,
     "end_time": "2021-01-25T02:31:13.532467",
     "exception": false,
     "start_time": "2021-01-25T02:31:13.257814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 456, 456, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 228, 228, 48) 1296        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 228, 228, 48) 192         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 228, 228, 48) 0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 228, 228, 48) 432         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 228, 228, 48) 192         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 228, 228, 48) 0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 48)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 48)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 12)     588         block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 48)     624         block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 228, 228, 48) 0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 228, 228, 24) 1152        block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 228, 228, 24) 96          block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_dwconv (DepthwiseConv2D (None, 228, 228, 24) 216         block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_bn (BatchNormalization) (None, 228, 228, 24) 96          block1b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1b_activation (Activation) (None, 228, 228, 24) 0           block1b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_squeeze (GlobalAvera (None, 24)           0           block1b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reshape (Reshape)    (None, 1, 1, 24)     0           block1b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reduce (Conv2D)      (None, 1, 1, 6)      150         block1b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_expand (Conv2D)      (None, 1, 1, 24)     168         block1b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_excite (Multiply)    (None, 228, 228, 24) 0           block1b_activation[0][0]         \n",
      "                                                                 block1b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_conv (Conv2D)   (None, 228, 228, 24) 576         block1b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_bn (BatchNormal (None, 228, 228, 24) 96          block1b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_drop (FixedDropout)     (None, 228, 228, 24) 0           block1b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_add (Add)               (None, 228, 228, 24) 0           block1b_drop[0][0]               \n",
      "                                                                 block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_dwconv (DepthwiseConv2D (None, 228, 228, 24) 216         block1b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block1c_bn (BatchNormalization) (None, 228, 228, 24) 96          block1c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1c_activation (Activation) (None, 228, 228, 24) 0           block1c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_squeeze (GlobalAvera (None, 24)           0           block1c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_reshape (Reshape)    (None, 1, 1, 24)     0           block1c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_reduce (Conv2D)      (None, 1, 1, 6)      150         block1c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_expand (Conv2D)      (None, 1, 1, 24)     168         block1c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_excite (Multiply)    (None, 228, 228, 24) 0           block1c_activation[0][0]         \n",
      "                                                                 block1c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1c_project_conv (Conv2D)   (None, 228, 228, 24) 576         block1c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1c_project_bn (BatchNormal (None, 228, 228, 24) 96          block1c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1c_drop (FixedDropout)     (None, 228, 228, 24) 0           block1c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_add (Add)               (None, 228, 228, 24) 0           block1c_drop[0][0]               \n",
      "                                                                 block1b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 228, 228, 144 3456        block1c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 228, 228, 144 576         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 228, 228, 144 0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 114, 114, 144 1296        block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 114, 114, 144 576         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 114, 114, 144 0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 144)          0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 114, 114, 144 0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 114, 114, 40) 5760        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 114, 114, 40) 160         block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 114, 114, 240 9600        block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 114, 114, 240 960         block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 114, 114, 240 0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 114, 114, 240 2160        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 114, 114, 240 960         block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 114, 114, 240 0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 240)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 240)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 114, 114, 240 0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 114, 114, 40) 9600        block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 114, 114, 40) 160         block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (FixedDropout)     (None, 114, 114, 40) 0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 114, 114, 40) 0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_conv (Conv2D)    (None, 114, 114, 240 9600        block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_bn (BatchNormali (None, 114, 114, 240 960         block2c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_activation (Acti (None, 114, 114, 240 0           block2c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_dwconv (DepthwiseConv2D (None, 114, 114, 240 2160        block2c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2c_bn (BatchNormalization) (None, 114, 114, 240 960         block2c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2c_activation (Activation) (None, 114, 114, 240 0           block2c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_squeeze (GlobalAvera (None, 240)          0           block2c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reshape (Reshape)    (None, 1, 1, 240)    0           block2c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block2c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block2c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_excite (Multiply)    (None, 114, 114, 240 0           block2c_activation[0][0]         \n",
      "                                                                 block2c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_conv (Conv2D)   (None, 114, 114, 40) 9600        block2c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_bn (BatchNormal (None, 114, 114, 40) 160         block2c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2c_drop (FixedDropout)     (None, 114, 114, 40) 0           block2c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_add (Add)               (None, 114, 114, 40) 0           block2c_drop[0][0]               \n",
      "                                                                 block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_conv (Conv2D)    (None, 114, 114, 240 9600        block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_bn (BatchNormali (None, 114, 114, 240 960         block2d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_activation (Acti (None, 114, 114, 240 0           block2d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_dwconv (DepthwiseConv2D (None, 114, 114, 240 2160        block2d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2d_bn (BatchNormalization) (None, 114, 114, 240 960         block2d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2d_activation (Activation) (None, 114, 114, 240 0           block2d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_squeeze (GlobalAvera (None, 240)          0           block2d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_reshape (Reshape)    (None, 1, 1, 240)    0           block2d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block2d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block2d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_excite (Multiply)    (None, 114, 114, 240 0           block2d_activation[0][0]         \n",
      "                                                                 block2d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_project_conv (Conv2D)   (None, 114, 114, 40) 9600        block2d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_project_bn (BatchNormal (None, 114, 114, 40) 160         block2d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2d_drop (FixedDropout)     (None, 114, 114, 40) 0           block2d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_add (Add)               (None, 114, 114, 40) 0           block2d_drop[0][0]               \n",
      "                                                                 block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2e_expand_conv (Conv2D)    (None, 114, 114, 240 9600        block2d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2e_expand_bn (BatchNormali (None, 114, 114, 240 960         block2e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2e_expand_activation (Acti (None, 114, 114, 240 0           block2e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_dwconv (DepthwiseConv2D (None, 114, 114, 240 2160        block2e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2e_bn (BatchNormalization) (None, 114, 114, 240 960         block2e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2e_activation (Activation) (None, 114, 114, 240 0           block2e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_squeeze (GlobalAvera (None, 240)          0           block2e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_reshape (Reshape)    (None, 1, 1, 240)    0           block2e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block2e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block2e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_excite (Multiply)    (None, 114, 114, 240 0           block2e_activation[0][0]         \n",
      "                                                                 block2e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_project_conv (Conv2D)   (None, 114, 114, 40) 9600        block2e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_project_bn (BatchNormal (None, 114, 114, 40) 160         block2e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2e_drop (FixedDropout)     (None, 114, 114, 40) 0           block2e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_add (Add)               (None, 114, 114, 40) 0           block2e_drop[0][0]               \n",
      "                                                                 block2d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 114, 114, 240 9600        block2e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 114, 114, 240 960         block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 114, 114, 240 0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 57, 57, 240)  6000        block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 57, 57, 240)  960         block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 57, 57, 240)  0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 240)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 240)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 57, 57, 240)  0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 57, 57, 64)   15360       block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 57, 57, 64)   256         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 57, 57, 384)  24576       block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 57, 57, 384)  1536        block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 57, 57, 384)  0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 57, 57, 384)  9600        block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 57, 57, 384)  1536        block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 57, 57, 384)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 384)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 384)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 16)     6160        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 384)    6528        block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 57, 57, 384)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 57, 57, 64)   24576       block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 57, 57, 64)   256         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (FixedDropout)     (None, 57, 57, 64)   0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 57, 57, 64)   0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_conv (Conv2D)    (None, 57, 57, 384)  24576       block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_bn (BatchNormali (None, 57, 57, 384)  1536        block3c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_activation (Acti (None, 57, 57, 384)  0           block3c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_dwconv (DepthwiseConv2D (None, 57, 57, 384)  9600        block3c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3c_bn (BatchNormalization) (None, 57, 57, 384)  1536        block3c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3c_activation (Activation) (None, 57, 57, 384)  0           block3c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_squeeze (GlobalAvera (None, 384)          0           block3c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reshape (Reshape)    (None, 1, 1, 384)    0           block3c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reduce (Conv2D)      (None, 1, 1, 16)     6160        block3c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_expand (Conv2D)      (None, 1, 1, 384)    6528        block3c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_excite (Multiply)    (None, 57, 57, 384)  0           block3c_activation[0][0]         \n",
      "                                                                 block3c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_conv (Conv2D)   (None, 57, 57, 64)   24576       block3c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_bn (BatchNormal (None, 57, 57, 64)   256         block3c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3c_drop (FixedDropout)     (None, 57, 57, 64)   0           block3c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_add (Add)               (None, 57, 57, 64)   0           block3c_drop[0][0]               \n",
      "                                                                 block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_conv (Conv2D)    (None, 57, 57, 384)  24576       block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_bn (BatchNormali (None, 57, 57, 384)  1536        block3d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_activation (Acti (None, 57, 57, 384)  0           block3d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_dwconv (DepthwiseConv2D (None, 57, 57, 384)  9600        block3d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3d_bn (BatchNormalization) (None, 57, 57, 384)  1536        block3d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3d_activation (Activation) (None, 57, 57, 384)  0           block3d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_squeeze (GlobalAvera (None, 384)          0           block3d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_reshape (Reshape)    (None, 1, 1, 384)    0           block3d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_reduce (Conv2D)      (None, 1, 1, 16)     6160        block3d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_expand (Conv2D)      (None, 1, 1, 384)    6528        block3d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_excite (Multiply)    (None, 57, 57, 384)  0           block3d_activation[0][0]         \n",
      "                                                                 block3d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_project_conv (Conv2D)   (None, 57, 57, 64)   24576       block3d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_project_bn (BatchNormal (None, 57, 57, 64)   256         block3d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3d_drop (FixedDropout)     (None, 57, 57, 64)   0           block3d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_add (Add)               (None, 57, 57, 64)   0           block3d_drop[0][0]               \n",
      "                                                                 block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3e_expand_conv (Conv2D)    (None, 57, 57, 384)  24576       block3d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3e_expand_bn (BatchNormali (None, 57, 57, 384)  1536        block3e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3e_expand_activation (Acti (None, 57, 57, 384)  0           block3e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_dwconv (DepthwiseConv2D (None, 57, 57, 384)  9600        block3e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3e_bn (BatchNormalization) (None, 57, 57, 384)  1536        block3e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3e_activation (Activation) (None, 57, 57, 384)  0           block3e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_squeeze (GlobalAvera (None, 384)          0           block3e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_reshape (Reshape)    (None, 1, 1, 384)    0           block3e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_reduce (Conv2D)      (None, 1, 1, 16)     6160        block3e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_expand (Conv2D)      (None, 1, 1, 384)    6528        block3e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_excite (Multiply)    (None, 57, 57, 384)  0           block3e_activation[0][0]         \n",
      "                                                                 block3e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_project_conv (Conv2D)   (None, 57, 57, 64)   24576       block3e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_project_bn (BatchNormal (None, 57, 57, 64)   256         block3e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3e_drop (FixedDropout)     (None, 57, 57, 64)   0           block3e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_add (Add)               (None, 57, 57, 64)   0           block3e_drop[0][0]               \n",
      "                                                                 block3d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 57, 57, 384)  24576       block3e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 57, 57, 384)  1536        block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 57, 57, 384)  0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 29, 29, 384)  3456        block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 29, 29, 384)  1536        block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 29, 29, 384)  0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 384)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 384)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 16)     6160        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 384)    6528        block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 29, 29, 384)  0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 29, 29, 128)  49152       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 29, 29, 128)  512         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 29, 29, 768)  98304       block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 29, 29, 768)  3072        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 29, 29, 768)  0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 29, 29, 768)  6912        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 29, 29, 768)  3072        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 29, 29, 768)  0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 768)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 768)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 32)     24608       block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 768)    25344       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 29, 29, 768)  0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 29, 29, 128)  98304       block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 29, 29, 128)  512         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (FixedDropout)     (None, 29, 29, 128)  0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 29, 29, 128)  0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 29, 29, 768)  98304       block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 29, 29, 768)  3072        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 29, 29, 768)  0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 29, 29, 768)  6912        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 29, 29, 768)  3072        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 29, 29, 768)  0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 768)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 768)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 32)     24608       block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 768)    25344       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 29, 29, 768)  0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 29, 29, 128)  98304       block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 29, 29, 128)  512         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (FixedDropout)     (None, 29, 29, 128)  0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 29, 29, 128)  0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_conv (Conv2D)    (None, 29, 29, 768)  98304       block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_bn (BatchNormali (None, 29, 29, 768)  3072        block4d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_activation (Acti (None, 29, 29, 768)  0           block4d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_dwconv (DepthwiseConv2D (None, 29, 29, 768)  6912        block4d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4d_bn (BatchNormalization) (None, 29, 29, 768)  3072        block4d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4d_activation (Activation) (None, 29, 29, 768)  0           block4d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_squeeze (GlobalAvera (None, 768)          0           block4d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reshape (Reshape)    (None, 1, 1, 768)    0           block4d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reduce (Conv2D)      (None, 1, 1, 32)     24608       block4d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_expand (Conv2D)      (None, 1, 1, 768)    25344       block4d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_excite (Multiply)    (None, 29, 29, 768)  0           block4d_activation[0][0]         \n",
      "                                                                 block4d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_conv (Conv2D)   (None, 29, 29, 128)  98304       block4d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_bn (BatchNormal (None, 29, 29, 128)  512         block4d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4d_drop (FixedDropout)     (None, 29, 29, 128)  0           block4d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_add (Add)               (None, 29, 29, 128)  0           block4d_drop[0][0]               \n",
      "                                                                 block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_conv (Conv2D)    (None, 29, 29, 768)  98304       block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_bn (BatchNormali (None, 29, 29, 768)  3072        block4e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_activation (Acti (None, 29, 29, 768)  0           block4e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_dwconv (DepthwiseConv2D (None, 29, 29, 768)  6912        block4e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4e_bn (BatchNormalization) (None, 29, 29, 768)  3072        block4e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4e_activation (Activation) (None, 29, 29, 768)  0           block4e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_squeeze (GlobalAvera (None, 768)          0           block4e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reshape (Reshape)    (None, 1, 1, 768)    0           block4e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reduce (Conv2D)      (None, 1, 1, 32)     24608       block4e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_expand (Conv2D)      (None, 1, 1, 768)    25344       block4e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_excite (Multiply)    (None, 29, 29, 768)  0           block4e_activation[0][0]         \n",
      "                                                                 block4e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_conv (Conv2D)   (None, 29, 29, 128)  98304       block4e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_bn (BatchNormal (None, 29, 29, 128)  512         block4e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4e_drop (FixedDropout)     (None, 29, 29, 128)  0           block4e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_add (Add)               (None, 29, 29, 128)  0           block4e_drop[0][0]               \n",
      "                                                                 block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_conv (Conv2D)    (None, 29, 29, 768)  98304       block4e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_bn (BatchNormali (None, 29, 29, 768)  3072        block4f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_activation (Acti (None, 29, 29, 768)  0           block4f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_dwconv (DepthwiseConv2D (None, 29, 29, 768)  6912        block4f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4f_bn (BatchNormalization) (None, 29, 29, 768)  3072        block4f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4f_activation (Activation) (None, 29, 29, 768)  0           block4f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_squeeze (GlobalAvera (None, 768)          0           block4f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_reshape (Reshape)    (None, 1, 1, 768)    0           block4f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_reduce (Conv2D)      (None, 1, 1, 32)     24608       block4f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_expand (Conv2D)      (None, 1, 1, 768)    25344       block4f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_excite (Multiply)    (None, 29, 29, 768)  0           block4f_activation[0][0]         \n",
      "                                                                 block4f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_project_conv (Conv2D)   (None, 29, 29, 128)  98304       block4f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_project_bn (BatchNormal (None, 29, 29, 128)  512         block4f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4f_drop (FixedDropout)     (None, 29, 29, 128)  0           block4f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_add (Add)               (None, 29, 29, 128)  0           block4f_drop[0][0]               \n",
      "                                                                 block4e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4g_expand_conv (Conv2D)    (None, 29, 29, 768)  98304       block4f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4g_expand_bn (BatchNormali (None, 29, 29, 768)  3072        block4g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4g_expand_activation (Acti (None, 29, 29, 768)  0           block4g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_dwconv (DepthwiseConv2D (None, 29, 29, 768)  6912        block4g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4g_bn (BatchNormalization) (None, 29, 29, 768)  3072        block4g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4g_activation (Activation) (None, 29, 29, 768)  0           block4g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_squeeze (GlobalAvera (None, 768)          0           block4g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_reshape (Reshape)    (None, 1, 1, 768)    0           block4g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_reduce (Conv2D)      (None, 1, 1, 32)     24608       block4g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_expand (Conv2D)      (None, 1, 1, 768)    25344       block4g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_excite (Multiply)    (None, 29, 29, 768)  0           block4g_activation[0][0]         \n",
      "                                                                 block4g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_project_conv (Conv2D)   (None, 29, 29, 128)  98304       block4g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_project_bn (BatchNormal (None, 29, 29, 128)  512         block4g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4g_drop (FixedDropout)     (None, 29, 29, 128)  0           block4g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_add (Add)               (None, 29, 29, 128)  0           block4g_drop[0][0]               \n",
      "                                                                 block4f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 29, 29, 768)  98304       block4g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 29, 29, 768)  3072        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 29, 29, 768)  0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 29, 29, 768)  19200       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 29, 29, 768)  3072        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 29, 29, 768)  0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 768)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 768)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 32)     24608       block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 768)    25344       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 29, 29, 768)  0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 29, 29, 176)  135168      block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 29, 29, 176)  704         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 29, 29, 1056) 185856      block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 29, 29, 1056) 4224        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 29, 29, 1056) 0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 29, 29, 1056) 26400       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 29, 29, 1056) 4224        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 29, 29, 1056) 0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 1056)         0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 1056)   0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 44)     46508       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 1056)   47520       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 29, 29, 1056) 0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 29, 29, 176)  185856      block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 29, 29, 176)  704         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (FixedDropout)     (None, 29, 29, 176)  0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 29, 29, 176)  0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 29, 29, 1056) 185856      block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 29, 29, 1056) 4224        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 29, 29, 1056) 0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 29, 29, 1056) 26400       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 29, 29, 1056) 4224        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 29, 29, 1056) 0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 1056)         0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 1056)   0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 44)     46508       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 1056)   47520       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 29, 29, 1056) 0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 29, 29, 176)  185856      block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 29, 29, 176)  704         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (FixedDropout)     (None, 29, 29, 176)  0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 29, 29, 176)  0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_conv (Conv2D)    (None, 29, 29, 1056) 185856      block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_bn (BatchNormali (None, 29, 29, 1056) 4224        block5d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_activation (Acti (None, 29, 29, 1056) 0           block5d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_dwconv (DepthwiseConv2D (None, 29, 29, 1056) 26400       block5d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5d_bn (BatchNormalization) (None, 29, 29, 1056) 4224        block5d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5d_activation (Activation) (None, 29, 29, 1056) 0           block5d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_squeeze (GlobalAvera (None, 1056)         0           block5d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reshape (Reshape)    (None, 1, 1, 1056)   0           block5d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reduce (Conv2D)      (None, 1, 1, 44)     46508       block5d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_expand (Conv2D)      (None, 1, 1, 1056)   47520       block5d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_excite (Multiply)    (None, 29, 29, 1056) 0           block5d_activation[0][0]         \n",
      "                                                                 block5d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_conv (Conv2D)   (None, 29, 29, 176)  185856      block5d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_bn (BatchNormal (None, 29, 29, 176)  704         block5d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5d_drop (FixedDropout)     (None, 29, 29, 176)  0           block5d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_add (Add)               (None, 29, 29, 176)  0           block5d_drop[0][0]               \n",
      "                                                                 block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_conv (Conv2D)    (None, 29, 29, 1056) 185856      block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_bn (BatchNormali (None, 29, 29, 1056) 4224        block5e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_activation (Acti (None, 29, 29, 1056) 0           block5e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_dwconv (DepthwiseConv2D (None, 29, 29, 1056) 26400       block5e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5e_bn (BatchNormalization) (None, 29, 29, 1056) 4224        block5e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5e_activation (Activation) (None, 29, 29, 1056) 0           block5e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_squeeze (GlobalAvera (None, 1056)         0           block5e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reshape (Reshape)    (None, 1, 1, 1056)   0           block5e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reduce (Conv2D)      (None, 1, 1, 44)     46508       block5e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_expand (Conv2D)      (None, 1, 1, 1056)   47520       block5e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_excite (Multiply)    (None, 29, 29, 1056) 0           block5e_activation[0][0]         \n",
      "                                                                 block5e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_conv (Conv2D)   (None, 29, 29, 176)  185856      block5e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_bn (BatchNormal (None, 29, 29, 176)  704         block5e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5e_drop (FixedDropout)     (None, 29, 29, 176)  0           block5e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_add (Add)               (None, 29, 29, 176)  0           block5e_drop[0][0]               \n",
      "                                                                 block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_conv (Conv2D)    (None, 29, 29, 1056) 185856      block5e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_bn (BatchNormali (None, 29, 29, 1056) 4224        block5f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_activation (Acti (None, 29, 29, 1056) 0           block5f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_dwconv (DepthwiseConv2D (None, 29, 29, 1056) 26400       block5f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5f_bn (BatchNormalization) (None, 29, 29, 1056) 4224        block5f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5f_activation (Activation) (None, 29, 29, 1056) 0           block5f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_squeeze (GlobalAvera (None, 1056)         0           block5f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_reshape (Reshape)    (None, 1, 1, 1056)   0           block5f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_reduce (Conv2D)      (None, 1, 1, 44)     46508       block5f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_expand (Conv2D)      (None, 1, 1, 1056)   47520       block5f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_excite (Multiply)    (None, 29, 29, 1056) 0           block5f_activation[0][0]         \n",
      "                                                                 block5f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_project_conv (Conv2D)   (None, 29, 29, 176)  185856      block5f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_project_bn (BatchNormal (None, 29, 29, 176)  704         block5f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5f_drop (FixedDropout)     (None, 29, 29, 176)  0           block5f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_add (Add)               (None, 29, 29, 176)  0           block5f_drop[0][0]               \n",
      "                                                                 block5e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5g_expand_conv (Conv2D)    (None, 29, 29, 1056) 185856      block5f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5g_expand_bn (BatchNormali (None, 29, 29, 1056) 4224        block5g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5g_expand_activation (Acti (None, 29, 29, 1056) 0           block5g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_dwconv (DepthwiseConv2D (None, 29, 29, 1056) 26400       block5g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5g_bn (BatchNormalization) (None, 29, 29, 1056) 4224        block5g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5g_activation (Activation) (None, 29, 29, 1056) 0           block5g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_squeeze (GlobalAvera (None, 1056)         0           block5g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_reshape (Reshape)    (None, 1, 1, 1056)   0           block5g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_reduce (Conv2D)      (None, 1, 1, 44)     46508       block5g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_expand (Conv2D)      (None, 1, 1, 1056)   47520       block5g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_excite (Multiply)    (None, 29, 29, 1056) 0           block5g_activation[0][0]         \n",
      "                                                                 block5g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_project_conv (Conv2D)   (None, 29, 29, 176)  185856      block5g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_project_bn (BatchNormal (None, 29, 29, 176)  704         block5g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5g_drop (FixedDropout)     (None, 29, 29, 176)  0           block5g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_add (Add)               (None, 29, 29, 176)  0           block5g_drop[0][0]               \n",
      "                                                                 block5f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 29, 29, 1056) 185856      block5g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 29, 29, 1056) 4224        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 29, 29, 1056) 0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 15, 15, 1056) 26400       block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 15, 15, 1056) 4224        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 15, 15, 1056) 0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 1056)         0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 1056)   0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 44)     46508       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 1056)   47520       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 15, 15, 1056) 0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 15, 15, 304)  321024      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 15, 15, 304)  1216        block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 15, 15, 1824) 554496      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 15, 15, 1824) 7296        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 15, 15, 1824) 0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 15, 15, 1824) 45600       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 15, 15, 1824) 7296        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 15, 15, 1824) 0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 1824)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 1824)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 76)     138700      block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 1824)   140448      block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 15, 15, 1824) 0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 15, 15, 304)  554496      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 15, 15, 304)  1216        block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (FixedDropout)     (None, 15, 15, 304)  0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 15, 15, 304)  0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 15, 15, 1824) 554496      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 15, 15, 1824) 7296        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 15, 15, 1824) 0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 15, 15, 1824) 45600       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 15, 15, 1824) 7296        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 15, 15, 1824) 0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 1824)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 1824)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 76)     138700      block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 1824)   140448      block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 15, 15, 1824) 0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 15, 15, 304)  554496      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 15, 15, 304)  1216        block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (FixedDropout)     (None, 15, 15, 304)  0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 15, 15, 304)  0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 15, 15, 1824) 554496      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 15, 15, 1824) 7296        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 15, 15, 1824) 0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 15, 15, 1824) 45600       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 15, 15, 1824) 7296        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 15, 15, 1824) 0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 1824)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 1824)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 76)     138700      block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 1824)   140448      block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 15, 15, 1824) 0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 15, 15, 304)  554496      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 15, 15, 304)  1216        block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (FixedDropout)     (None, 15, 15, 304)  0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 15, 15, 304)  0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_conv (Conv2D)    (None, 15, 15, 1824) 554496      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_bn (BatchNormali (None, 15, 15, 1824) 7296        block6e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_activation (Acti (None, 15, 15, 1824) 0           block6e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_dwconv (DepthwiseConv2D (None, 15, 15, 1824) 45600       block6e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6e_bn (BatchNormalization) (None, 15, 15, 1824) 7296        block6e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6e_activation (Activation) (None, 15, 15, 1824) 0           block6e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_squeeze (GlobalAvera (None, 1824)         0           block6e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reshape (Reshape)    (None, 1, 1, 1824)   0           block6e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reduce (Conv2D)      (None, 1, 1, 76)     138700      block6e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_expand (Conv2D)      (None, 1, 1, 1824)   140448      block6e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_excite (Multiply)    (None, 15, 15, 1824) 0           block6e_activation[0][0]         \n",
      "                                                                 block6e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_conv (Conv2D)   (None, 15, 15, 304)  554496      block6e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_bn (BatchNormal (None, 15, 15, 304)  1216        block6e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6e_drop (FixedDropout)     (None, 15, 15, 304)  0           block6e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_add (Add)               (None, 15, 15, 304)  0           block6e_drop[0][0]               \n",
      "                                                                 block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_conv (Conv2D)    (None, 15, 15, 1824) 554496      block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_bn (BatchNormali (None, 15, 15, 1824) 7296        block6f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_activation (Acti (None, 15, 15, 1824) 0           block6f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_dwconv (DepthwiseConv2D (None, 15, 15, 1824) 45600       block6f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6f_bn (BatchNormalization) (None, 15, 15, 1824) 7296        block6f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6f_activation (Activation) (None, 15, 15, 1824) 0           block6f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_squeeze (GlobalAvera (None, 1824)         0           block6f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reshape (Reshape)    (None, 1, 1, 1824)   0           block6f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reduce (Conv2D)      (None, 1, 1, 76)     138700      block6f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_expand (Conv2D)      (None, 1, 1, 1824)   140448      block6f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_excite (Multiply)    (None, 15, 15, 1824) 0           block6f_activation[0][0]         \n",
      "                                                                 block6f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_conv (Conv2D)   (None, 15, 15, 304)  554496      block6f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_bn (BatchNormal (None, 15, 15, 304)  1216        block6f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6f_drop (FixedDropout)     (None, 15, 15, 304)  0           block6f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_add (Add)               (None, 15, 15, 304)  0           block6f_drop[0][0]               \n",
      "                                                                 block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_conv (Conv2D)    (None, 15, 15, 1824) 554496      block6f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_bn (BatchNormali (None, 15, 15, 1824) 7296        block6g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_activation (Acti (None, 15, 15, 1824) 0           block6g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_dwconv (DepthwiseConv2D (None, 15, 15, 1824) 45600       block6g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6g_bn (BatchNormalization) (None, 15, 15, 1824) 7296        block6g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6g_activation (Activation) (None, 15, 15, 1824) 0           block6g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_squeeze (GlobalAvera (None, 1824)         0           block6g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_reshape (Reshape)    (None, 1, 1, 1824)   0           block6g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_reduce (Conv2D)      (None, 1, 1, 76)     138700      block6g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_expand (Conv2D)      (None, 1, 1, 1824)   140448      block6g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_excite (Multiply)    (None, 15, 15, 1824) 0           block6g_activation[0][0]         \n",
      "                                                                 block6g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_project_conv (Conv2D)   (None, 15, 15, 304)  554496      block6g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_project_bn (BatchNormal (None, 15, 15, 304)  1216        block6g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6g_drop (FixedDropout)     (None, 15, 15, 304)  0           block6g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_add (Add)               (None, 15, 15, 304)  0           block6g_drop[0][0]               \n",
      "                                                                 block6f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_conv (Conv2D)    (None, 15, 15, 1824) 554496      block6g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_bn (BatchNormali (None, 15, 15, 1824) 7296        block6h_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_activation (Acti (None, 15, 15, 1824) 0           block6h_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_dwconv (DepthwiseConv2D (None, 15, 15, 1824) 45600       block6h_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6h_bn (BatchNormalization) (None, 15, 15, 1824) 7296        block6h_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6h_activation (Activation) (None, 15, 15, 1824) 0           block6h_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_squeeze (GlobalAvera (None, 1824)         0           block6h_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_reshape (Reshape)    (None, 1, 1, 1824)   0           block6h_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_reduce (Conv2D)      (None, 1, 1, 76)     138700      block6h_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_expand (Conv2D)      (None, 1, 1, 1824)   140448      block6h_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_excite (Multiply)    (None, 15, 15, 1824) 0           block6h_activation[0][0]         \n",
      "                                                                 block6h_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_project_conv (Conv2D)   (None, 15, 15, 304)  554496      block6h_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_project_bn (BatchNormal (None, 15, 15, 304)  1216        block6h_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6h_drop (FixedDropout)     (None, 15, 15, 304)  0           block6h_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_add (Add)               (None, 15, 15, 304)  0           block6h_drop[0][0]               \n",
      "                                                                 block6g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6i_expand_conv (Conv2D)    (None, 15, 15, 1824) 554496      block6h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6i_expand_bn (BatchNormali (None, 15, 15, 1824) 7296        block6i_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6i_expand_activation (Acti (None, 15, 15, 1824) 0           block6i_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_dwconv (DepthwiseConv2D (None, 15, 15, 1824) 45600       block6i_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6i_bn (BatchNormalization) (None, 15, 15, 1824) 7296        block6i_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6i_activation (Activation) (None, 15, 15, 1824) 0           block6i_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_squeeze (GlobalAvera (None, 1824)         0           block6i_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_reshape (Reshape)    (None, 1, 1, 1824)   0           block6i_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_reduce (Conv2D)      (None, 1, 1, 76)     138700      block6i_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_expand (Conv2D)      (None, 1, 1, 1824)   140448      block6i_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_excite (Multiply)    (None, 15, 15, 1824) 0           block6i_activation[0][0]         \n",
      "                                                                 block6i_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_project_conv (Conv2D)   (None, 15, 15, 304)  554496      block6i_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_project_bn (BatchNormal (None, 15, 15, 304)  1216        block6i_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6i_drop (FixedDropout)     (None, 15, 15, 304)  0           block6i_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_add (Add)               (None, 15, 15, 304)  0           block6i_drop[0][0]               \n",
      "                                                                 block6h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 15, 15, 1824) 554496      block6i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 15, 15, 1824) 7296        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 15, 15, 1824) 0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 15, 15, 1824) 16416       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 15, 15, 1824) 7296        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 15, 15, 1824) 0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 1824)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 1824)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 76)     138700      block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 1824)   140448      block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 15, 15, 1824) 0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 15, 15, 512)  933888      block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 15, 15, 512)  2048        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_conv (Conv2D)    (None, 15, 15, 3072) 1572864     block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_bn (BatchNormali (None, 15, 15, 3072) 12288       block7b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_activation (Acti (None, 15, 15, 3072) 0           block7b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_dwconv (DepthwiseConv2D (None, 15, 15, 3072) 27648       block7b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7b_bn (BatchNormalization) (None, 15, 15, 3072) 12288       block7b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7b_activation (Activation) (None, 15, 15, 3072) 0           block7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_squeeze (GlobalAvera (None, 3072)         0           block7b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reshape (Reshape)    (None, 1, 1, 3072)   0           block7b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reduce (Conv2D)      (None, 1, 1, 128)    393344      block7b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_expand (Conv2D)      (None, 1, 1, 3072)   396288      block7b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_excite (Multiply)    (None, 15, 15, 3072) 0           block7b_activation[0][0]         \n",
      "                                                                 block7b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_conv (Conv2D)   (None, 15, 15, 512)  1572864     block7b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_bn (BatchNormal (None, 15, 15, 512)  2048        block7b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_drop (FixedDropout)     (None, 15, 15, 512)  0           block7b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_add (Add)               (None, 15, 15, 512)  0           block7b_drop[0][0]               \n",
      "                                                                 block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_expand_conv (Conv2D)    (None, 15, 15, 3072) 1572864     block7b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7c_expand_bn (BatchNormali (None, 15, 15, 3072) 12288       block7c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7c_expand_activation (Acti (None, 15, 15, 3072) 0           block7c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_dwconv (DepthwiseConv2D (None, 15, 15, 3072) 27648       block7c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7c_bn (BatchNormalization) (None, 15, 15, 3072) 12288       block7c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7c_activation (Activation) (None, 15, 15, 3072) 0           block7c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_squeeze (GlobalAvera (None, 3072)         0           block7c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_reshape (Reshape)    (None, 1, 1, 3072)   0           block7c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_reduce (Conv2D)      (None, 1, 1, 128)    393344      block7c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_expand (Conv2D)      (None, 1, 1, 3072)   396288      block7c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_excite (Multiply)    (None, 15, 15, 3072) 0           block7c_activation[0][0]         \n",
      "                                                                 block7c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_project_conv (Conv2D)   (None, 15, 15, 512)  1572864     block7c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_project_bn (BatchNormal (None, 15, 15, 512)  2048        block7c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7c_drop (FixedDropout)     (None, 15, 15, 512)  0           block7c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_add (Add)               (None, 15, 15, 512)  0           block7c_drop[0][0]               \n",
      "                                                                 block7b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 15, 15, 2048) 1048576     block7c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 15, 15, 2048) 8192        top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 15, 15, 2048) 0           top_bn[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           top_activation[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          1049088     global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 5)            2565        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 29,565,173\n",
      "Trainable params: 23,704,017\n",
      "Non-trainable params: 5,861,156\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build(input_shape)\n",
    "model.summary()\n",
    "#model.save('efimodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:13.706495Z",
     "iopub.status.busy": "2021-01-25T02:31:13.705526Z",
     "iopub.status.idle": "2021-01-25T02:31:52.198039Z",
     "shell.execute_reply": "2021-01-25T02:31:52.197366Z"
    },
    "papermill": {
     "duration": 38.572302,
     "end_time": "2021-01-25T02:31:52.198266",
     "exception": false,
     "start_time": "2021-01-25T02:31:13.625964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "import tensorflow_addons as tfa\n",
    "from efficientnet.keras import EfficientNetB5\n",
    "from efficientnet.keras import center_crop_and_resize, preprocess_input\n",
    "# loading pretrained conv base model\n",
    "lr_scheduler = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-1, \n",
    "    decay_steps=10, \n",
    "    decay_rate=0.9)\n",
    "with strategy.scope():       \n",
    "    #EfficientNetB0\n",
    "    RESIZE=[456,456]\n",
    "    img_adjust_layer = tf.keras.layers.Lambda(preprocess_input, input_shape=[*RESIZE, 3])\n",
    "    #adjust=tf.keras.backend.expand_dims(x, axis=0),\n",
    "    base_model = EfficientNetB5(\n",
    "                    include_top=False, \n",
    "                    input_shape=(*RESIZE, 3),\n",
    "                    #weights='noisy-student'\n",
    "               )\n",
    "    #x = center_crop_and_resize(image, image_size=image_size)\n",
    "    base_model.trainable=False\n",
    "    model = tf.keras.Sequential([\n",
    "        #img_adjust_layer,\n",
    "        #tf.keras.layers.Lambda(lambda image:center_crop_and_resize(image, image_size=image_size)),\n",
    "        tf.keras.layers.BatchNormalization(renorm=True),\n",
    "        #tf.keras.layers.Reshape((,0)),\n",
    "        #tf.keras.layers.Reshape((*RESIZE,3), input_shape=(*IMAGE_SIZE,3)),\n",
    "        #tf.keras.layers.Reshape((1,224,224,3), input_shape=(*IMAGE_SIZE,3),\n",
    "        base_model,\n",
    "        #tf.keras.layers.Dropout(1-1e-2)\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        #tf.keras.layers.Dropout(0.2),\n",
    "        #tf.keras.layers.Dense(32, activation='swish'),\n",
    "        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n",
    "        #tf.keras.layers.BatchNormalization(renorm=True),\n",
    "        \n",
    "    ])\n",
    "    #radam = tfa.optimizers.RectifiedAdam(min_lr=0.017,)\n",
    "    #ranger = tfa.optimizers.Lookahead(radam, sync_period=6, slow_step_size=0.5)\n",
    "    #for i in range(4):\n",
    "    #    model.add( tf.keras.layers.Dense(8, activation='relu'))\n",
    "    #model.add(tf.keras.layers.Dense(len(CLASSES), activation='softmax'))\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(lr = 0.001),\n",
    "        loss='sparse_categorical_crossentropy',  \n",
    "        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:52.324811Z",
     "iopub.status.busy": "2021-01-25T02:31:52.319500Z",
     "iopub.status.idle": "2021-01-25T02:31:52.351216Z",
     "shell.execute_reply": "2021-01-25T02:31:52.350304Z"
    },
    "papermill": {
     "duration": 0.097683,
     "end_time": "2021-01-25T02:31:52.351346",
     "exception": false,
     "start_time": "2021-01-25T02:31:52.253663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "learn() missing 1 required positional argument: 'bs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-fee3f530d710>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: learn() missing 1 required positional argument: 'bs'"
     ]
    }
   ],
   "source": [
    "learn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:52.490307Z",
     "iopub.status.busy": "2021-01-25T02:31:52.489268Z",
     "iopub.status.idle": "2021-01-25T02:31:52.493296Z",
     "shell.execute_reply": "2021-01-25T02:31:52.492639Z"
    },
    "papermill": {
     "duration": 0.087446,
     "end_time": "2021-01-25T02:31:52.493417",
     "exception": false,
     "start_time": "2021-01-25T02:31:52.405971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CompareTv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-3dc772c8e8d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCompareTv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'CompareTv' is not defined"
     ]
    }
   ],
   "source": [
    "CompareTv(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:55.148067Z",
     "iopub.status.busy": "2021-01-25T02:31:55.142720Z",
     "iopub.status.idle": "2021-01-25T02:31:55.175489Z",
     "shell.execute_reply": "2021-01-25T02:31:55.174859Z"
    },
    "papermill": {
     "duration": 2.625583,
     "end_time": "2021-01-25T02:31:55.175617",
     "exception": false,
     "start_time": "2021-01-25T02:31:52.550034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "listdir: path should be string, bytes, os.PathLike, integer or None, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-53e279a7b4e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mTTA_STEPS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfiles_path\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGCS_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/train_images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: listdir: path should be string, bytes, os.PathLike, integer or None, not list"
     ]
    }
   ],
   "source": [
    "TTA_STEPS = 1 \n",
    "files_path =tf.io.gfile.glob(GCS_PATH + '/train_images')\n",
    "test_preds = np.zeros((len(os.listdir(files_path)), CLASSES))\n",
    "\n",
    "\n",
    "for model_path in model_path_list:\n",
    "    print(model_path)\n",
    "    K.clear_session()\n",
    "    model.load_weights(model_path)\n",
    "\n",
    "    if TTA_STEPS > 0:\n",
    "        test_ds = get_dataset(files_path, tta=True)\n",
    "        for step in range(TTA_STEPS):\n",
    "            print(f'TTA step {step+1}/{TTA_STEPS}')\n",
    "            x_test = test_ds.map(lambda image, image_name: image)\n",
    "            test_preds += model.predict(x_test) / (TTA_STEPS * len(model_path_list))\n",
    "    else:\n",
    "        test_ds = get_dataset(files_path, tta=False)\n",
    "        x_test = test_ds.map(lambda image, image_name: image)\n",
    "        test_preds += model.predict(x_test) / len(model_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:55.306882Z",
     "iopub.status.busy": "2021-01-25T02:31:55.305686Z",
     "iopub.status.idle": "2021-01-25T02:31:55.309767Z",
     "shell.execute_reply": "2021-01-25T02:31:55.309050Z"
    },
    "papermill": {
     "duration": 0.075796,
     "end_time": "2021-01-25T02:31:55.309896",
     "exception": false,
     "start_time": "2021-01-25T02:31:55.234100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def buildModel(lr, batch_size):  \n",
    "    \n",
    "    with strategy.scope():       \n",
    "    #img_adjust_layer = tf.keras.layers.Lambda(tf.keras.applications.densenet.preprocess_input, input_shape=[*IMAGE_SIZE, 3])\n",
    "    #base_model =tf.keras.applications.InceptionResNetV2(input_shape=(*IMAGE_SIZE, 3),weights='imagenet', include_top=False)\n",
    "    #base_model.trainable=False\n",
    "    #base_model = tf.keras.applications.ResNet50V2(weights='imagenet', include_top=False)\n",
    "    #base_model.trainable = False#過学習\n",
    "        base_model = DenseNet201(\n",
    "                input_shape=(*IMAGE_SIZE, 3),\n",
    "                weights='imagenet',\n",
    "                include_top=False\n",
    "            )\n",
    "        base_model.trainable=False\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.BatchNormalization(renorm=True),\n",
    "            #img_adjust_layer,\n",
    "            base_model,\n",
    "            #tf.keras.layers.Dropout(1-1e-2)\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n",
    "            #tf.keras.layers.BatchNormalization(renorm=True),\n",
    "\n",
    "        ])\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss='sparse_categorical_crossentropy',  \n",
    "        metrics=['accuracy'])\n",
    "    EPOCHS = 1\n",
    "    BATCH_SIZE=batch_size*strategy.num_replicas_in_sync\n",
    "    STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n",
    "    VALID_STEPS = NUM_VALIDATION_IMAGES // BATCH_SIZE\n",
    "    history = model.fit(train_dataset, \n",
    "                    steps_per_epoch=STEPS_PER_EPOCH, \n",
    "                    epochs=EPOCHS,\n",
    "                    #validation_data=valid_dataset,\n",
    "                    #validation_steps=VALID_STEPS,\n",
    "                    callbacks=callbacks_list\n",
    "                    )\n",
    "   \n",
    "    #訓練データでトレーニング\n",
    "    #model.fit(train_x, train_y,verbose=0, batch_size=int(batch_size))  \n",
    "    print('training finished')\n",
    "    #テストデータで精度を確認\n",
    "    valid_dataset_ds = valid_dataset.map(lambda image, idnum: image)\n",
    "    score = model.evaluate(valid_dataset_ds)\n",
    "    \n",
    "    #score[0]はloss\n",
    "    #score[1]はmean_absolute_error\n",
    "    #score[2]はmean_squered_error\n",
    "    return score[0]*(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:55.430535Z",
     "iopub.status.busy": "2021-01-25T02:31:55.429752Z",
     "iopub.status.idle": "2021-01-25T02:31:55.462201Z",
     "shell.execute_reply": "2021-01-25T02:31:55.461605Z"
    },
    "papermill": {
     "duration": 0.095253,
     "end_time": "2021-01-25T02:31:55.462315",
     "exception": false,
     "start_time": "2021-01-25T02:31:55.367062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "def bayesOpt():\n",
    "    pbounds = {\n",
    "        'batch_size' : (2,16),\n",
    "        'lr' : (1e-7, 1.0)\n",
    "    }\n",
    "    optimizer = BayesianOptimization(f=buildModel, pbounds=pbounds)\n",
    "    optimizer.maximize(init_points=5, n_iter=10, acq='ucb')\n",
    "    return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:55.588719Z",
     "iopub.status.busy": "2021-01-25T02:31:55.587691Z",
     "iopub.status.idle": "2021-01-25T02:31:55.660792Z",
     "shell.execute_reply": "2021-01-25T02:31:55.661489Z"
    },
    "papermill": {
     "duration": 0.142268,
     "end_time": "2021-01-25T02:31:55.661660",
     "exception": false,
     "start_time": "2021-01-25T02:31:55.519392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... |    lr     |\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'DenseNet201' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (11.960604332238045, 0.34572777193677323)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-d54ff51292f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbayesOpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-9a77744f9cef>\u001b[0m in \u001b[0;36mbayesOpt\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     }\n\u001b[1;32m      7\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuildModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ucb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bounds_transformer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-202b2a5cb505>\u001b[0m in \u001b[0;36mbuildModel\u001b[0;34m(lr, batch_size)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#base_model = tf.keras.applications.ResNet50V2(weights='imagenet', include_top=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#base_model.trainable = False#過学習\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         base_model = DenseNet201(\n\u001b[0m\u001b[1;32m     10\u001b[0m                 \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DenseNet201' is not defined"
     ]
    }
   ],
   "source": [
    "result = bayesOpt()\n",
    " \n",
    "result.res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:55.827258Z",
     "iopub.status.busy": "2021-01-25T02:31:55.787689Z",
     "iopub.status.idle": "2021-01-25T02:31:55.896734Z",
     "shell.execute_reply": "2021-01-25T02:31:55.896135Z"
    },
    "papermill": {
     "duration": 0.176575,
     "end_time": "2021-01-25T02:31:55.896849",
     "exception": false,
     "start_time": "2021-01-25T02:31:55.720274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-87ed3152812a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInitializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSwish\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropConnect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_model_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGENET_WEIGHTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconv_kernel_initializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_kernel_initializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Contains definitions for EfficientNet model.\n",
    "[1] Mingxing Tan, Quoc V. Le\n",
    "  EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks.\n",
    "  ICML'19, https://arxiv.org/abs/1905.11946\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import math\n",
    "import numpy as np\n",
    "import six\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.models as KM\n",
    "import tensorflow.keras.layers as KL\n",
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.keras.initializers import Initializer\n",
    "from .layers import Swish, DropConnect\n",
    "from .params import get_model_params, IMAGENET_WEIGHTS\n",
    "from .initializers import conv_kernel_initializer, dense_kernel_initializer\n",
    "\n",
    "\n",
    "__all__ = ['EfficientNet', 'EfficientNetB0', 'EfficientNetB1', 'EfficientNetB2', 'EfficientNetB3',\n",
    "           'EfficientNetB4', 'EfficientNetB5', 'EfficientNetB6', 'EfficientNetB7']\n",
    "\n",
    "class ConvKernalInitializer(Initializer):\n",
    "    def __call__(self, shape, dtype=K.floatx(), partition_info=None):\n",
    "        \"\"\"Initialization for convolutional kernels.\n",
    "        The main difference with tf.variance_scaling_initializer is that\n",
    "        tf.variance_scaling_initializer uses a truncated normal with an uncorrected\n",
    "        standard deviation, whereas here we use a normal distribution. Similarly,\n",
    "        tf.contrib.layers.variance_scaling_initializer uses a truncated normal with\n",
    "        a corrected standard deviation.\n",
    "        Args:\n",
    "        shape: shape of variable\n",
    "        dtype: dtype of variable\n",
    "        partition_info: unused\n",
    "        Returns:\n",
    "        an initialization for the variable\n",
    "        \"\"\"\n",
    "        del partition_info\n",
    "        kernel_height, kernel_width, _, out_filters = shape\n",
    "        fan_out = int(kernel_height * kernel_width * out_filters)\n",
    "        return tf.random.normal(\n",
    "            shape, mean=0.0, stddev=np.sqrt(2.0 / fan_out), dtype=dtype)\n",
    "\n",
    "class DenseKernalInitializer(Initializer):\n",
    "    def __call__(self, shape, dtype=K.floatx(), partition_info=None):\n",
    "        \"\"\"Initialization for dense kernels.\n",
    "        This initialization is equal to\n",
    "        tf.variance_scaling_initializer(scale=1.0/3.0, mode='fan_out',\n",
    "                                        distribution='uniform').\n",
    "        It is written out explicitly here for clarity.\n",
    "        Args:\n",
    "        shape: shape of variable\n",
    "        dtype: dtype of variable\n",
    "        partition_info: unused\n",
    "        Returns:\n",
    "        an initialization for the variable\n",
    "        \"\"\"\n",
    "        del partition_info\n",
    "        init_range = 1.0 / np.sqrt(shape[1])\n",
    "        return tf.random_uniform(shape, -init_range, init_range, dtype=dtype)\n",
    "\n",
    "\n",
    "def round_filters(filters, global_params):\n",
    "    \"\"\"Round number of filters based on depth multiplier.\"\"\"\n",
    "    orig_f = filters\n",
    "    multiplier = global_params.width_coefficient\n",
    "    divisor = global_params.depth_divisor\n",
    "    min_depth = global_params.min_depth\n",
    "    if not multiplier:\n",
    "        return filters\n",
    "\n",
    "    filters *= multiplier\n",
    "    min_depth = min_depth or divisor\n",
    "    new_filters = max(min_depth, int(filters + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_filters < 0.9 * filters:\n",
    "        new_filters += divisor\n",
    "    # print('round_filter input={} output={}'.format(orig_f, new_filters))\n",
    "    return int(new_filters)\n",
    "\n",
    "\n",
    "def round_repeats(repeats, global_params):\n",
    "    \"\"\"Round number of filters based on depth multiplier.\"\"\"\n",
    "    multiplier = global_params.depth_coefficient\n",
    "    if not multiplier:\n",
    "        return repeats\n",
    "    return int(math.ceil(multiplier * repeats))\n",
    "\n",
    "\n",
    "def SEBlock(block_args, global_params):\n",
    "    num_reduced_filters = max(\n",
    "        1, int(block_args.input_filters * block_args.se_ratio))\n",
    "    filters = block_args.input_filters * block_args.expand_ratio\n",
    "    if global_params.data_format == 'channels_first':\n",
    "        channel_axis = 1\n",
    "        spatial_dims = [2, 3]\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "        spatial_dims = [1, 2]\n",
    "\n",
    "    def block(inputs):\n",
    "        x = inputs\n",
    "        x = KL.Lambda(lambda a: K.mean(a, axis=spatial_dims, keepdims=True))(x)\n",
    "        x = KL.Conv2D(\n",
    "            num_reduced_filters,\n",
    "            kernel_size=[1, 1],\n",
    "            strides=[1, 1],\n",
    "            kernel_initializer=ConvKernalInitializer(),\n",
    "            padding='same',\n",
    "            use_bias=True\n",
    "        )(x)\n",
    "        x = Swish()(x)\n",
    "        # Excite\n",
    "        x = KL.Conv2D(\n",
    "            filters,\n",
    "            kernel_size=[1, 1],\n",
    "            strides=[1, 1],\n",
    "            kernel_initializer=ConvKernalInitializer(),\n",
    "            padding='same',\n",
    "            use_bias=True\n",
    "        )(x)\n",
    "        x = KL.Activation('sigmoid')(x)\n",
    "        out = KL.Multiply()([x, inputs])\n",
    "        return out\n",
    "\n",
    "    return block\n",
    "\n",
    "\n",
    "def MBConvBlock(block_args, global_params, drop_connect_rate=None):\n",
    "    batch_norm_momentum = global_params.batch_norm_momentum\n",
    "    batch_norm_epsilon = global_params.batch_norm_epsilon\n",
    "\n",
    "    if global_params.data_format == 'channels_first':\n",
    "        channel_axis = 1\n",
    "        spatial_dims = [2, 3]\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "        spatial_dims = [1, 2]\n",
    "\n",
    "    has_se = (block_args.se_ratio is not None) and (\n",
    "            block_args.se_ratio > 0) and (block_args.se_ratio <= 1)\n",
    "\n",
    "    filters = block_args.input_filters * block_args.expand_ratio\n",
    "    kernel_size = block_args.kernel_size\n",
    "\n",
    "    def block(inputs):\n",
    "\n",
    "        if block_args.expand_ratio != 1:\n",
    "            x = KL.Conv2D(\n",
    "                filters,\n",
    "                kernel_size=[1, 1],\n",
    "                strides=[1, 1],\n",
    "                kernel_initializer=ConvKernalInitializer(),\n",
    "                padding='same',\n",
    "                use_bias=False\n",
    "            )(inputs)\n",
    "            x = KL.BatchNormalization(\n",
    "                axis=channel_axis,\n",
    "                momentum=batch_norm_momentum,\n",
    "                epsilon=batch_norm_epsilon\n",
    "            )(x)\n",
    "            x = Swish()(x)\n",
    "        else:\n",
    "            x = inputs\n",
    "\n",
    "        x = KL.DepthwiseConv2D(\n",
    "            [kernel_size, kernel_size],\n",
    "            strides=block_args.strides,\n",
    "            depthwise_initializer=ConvKernalInitializer(),\n",
    "            padding='same',\n",
    "            use_bias=False\n",
    "        )(x)\n",
    "        x = KL.BatchNormalization(\n",
    "            axis=channel_axis,\n",
    "            momentum=batch_norm_momentum,\n",
    "            epsilon=batch_norm_epsilon\n",
    "        )(x)\n",
    "        x = Swish()(x)\n",
    "\n",
    "        if has_se:\n",
    "            x = SEBlock(block_args, global_params)(x)\n",
    "\n",
    "        # output phase\n",
    "\n",
    "        x = KL.Conv2D(\n",
    "            block_args.output_filters,\n",
    "            kernel_size=[1, 1],\n",
    "            strides=[1, 1],\n",
    "            kernel_initializer=ConvKernalInitializer(),\n",
    "            padding='same',\n",
    "            use_bias=False\n",
    "        )(x)\n",
    "        x = KL.BatchNormalization(\n",
    "            axis=channel_axis,\n",
    "            momentum=batch_norm_momentum,\n",
    "            epsilon=batch_norm_epsilon\n",
    "        )(x)\n",
    "\n",
    "        if block_args.id_skip:\n",
    "            if all(\n",
    "                    s == 1 for s in block_args.strides\n",
    "            ) and block_args.input_filters == block_args.output_filters:\n",
    "                # only apply drop_connect if skip presents.\n",
    "                if drop_connect_rate:\n",
    "                    x = DropConnect(drop_connect_rate)(x)\n",
    "                x = KL.Add()([x, inputs])\n",
    "        return x\n",
    "\n",
    "    return block\n",
    "\n",
    "\n",
    "def EfficientNet(input_shape, block_args_list, global_params, include_top=True, pooling=None):\n",
    "    batch_norm_momentum = global_params.batch_norm_momentum\n",
    "    batch_norm_epsilon = global_params.batch_norm_epsilon\n",
    "    if global_params.data_format == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    # Stem part\n",
    "    inputs = KL.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    x = KL.Conv2D(\n",
    "        filters=round_filters(32, global_params),\n",
    "        kernel_size=[3, 3],\n",
    "        strides=[2, 2],\n",
    "        kernel_initializer=ConvKernalInitializer(),\n",
    "        padding='same',\n",
    "        use_bias=False\n",
    "    )(x)\n",
    "    x = KL.BatchNormalization(\n",
    "        axis=channel_axis,\n",
    "        momentum=batch_norm_momentum,\n",
    "        epsilon=batch_norm_epsilon\n",
    "    )(x)\n",
    "    x = Swish()(x)\n",
    "\n",
    "    # Blocks part\n",
    "    block_idx = 1\n",
    "    n_blocks = sum([block_args.num_repeat for block_args in block_args_list])\n",
    "    drop_rate = global_params.drop_connect_rate or 0\n",
    "    drop_rate_dx = drop_rate / n_blocks\n",
    "\n",
    "    for block_args in block_args_list:\n",
    "        assert block_args.num_repeat > 0\n",
    "        # Update block input and output filters based on depth multiplier.\n",
    "        block_args = block_args._replace(\n",
    "            input_filters=round_filters(block_args.input_filters, global_params),\n",
    "            output_filters=round_filters(block_args.output_filters, global_params),\n",
    "            num_repeat=round_repeats(block_args.num_repeat, global_params)\n",
    "        )\n",
    "\n",
    "        # The first block needs to take care of stride and filter size increase.\n",
    "        x = MBConvBlock(block_args, global_params,\n",
    "                        drop_connect_rate=drop_rate_dx * block_idx)(x)\n",
    "        block_idx += 1\n",
    "\n",
    "        if block_args.num_repeat > 1:\n",
    "            block_args = block_args._replace(input_filters=block_args.output_filters, strides=[1, 1])\n",
    "\n",
    "        for _ in xrange(block_args.num_repeat - 1):\n",
    "            x = MBConvBlock(block_args, global_params,\n",
    "                            drop_connect_rate=drop_rate_dx * block_idx)(x)\n",
    "            block_idx += 1\n",
    "\n",
    "    # Head part\n",
    "    x = KL.Conv2D(\n",
    "        filters=round_filters(1280, global_params),\n",
    "        kernel_size=[1, 1],\n",
    "        strides=[1, 1],\n",
    "        kernel_initializer=ConvKernalInitializer(),\n",
    "        padding='same',\n",
    "        use_bias=False\n",
    "    )(x)\n",
    "    x = KL.BatchNormalization(\n",
    "        axis=channel_axis,\n",
    "        momentum=batch_norm_momentum,\n",
    "        epsilon=batch_norm_epsilon\n",
    "    )(x)\n",
    "    x = Swish()(x)\n",
    "\n",
    "    if include_top:\n",
    "        x = KL.GlobalAveragePooling2D(data_format=global_params.data_format)(x)\n",
    "        if global_params.dropout_rate > 0:\n",
    "            x = KL.Dropout(global_params.dropout_rate)(x)\n",
    "        x = KL.Dense(global_params.num_classes, kernel_initializer=DenseKernalInitializer())(x)\n",
    "        x = KL.Activation('softmax')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = KL.GlobalAveragePooling2D(data_format=global_params.data_format)(x)\n",
    "        elif pooling == 'max':\n",
    "            x = KL.GlobalMaxPooling2D(data_format=global_params.data_format)(x)\n",
    "\n",
    "    outputs = x\n",
    "    model = KM.Model(inputs, outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def _get_model_by_name(model_name, input_shape=None, include_top=True, weights=None, classes=1000, pooling=None):\n",
    "    \"\"\"Re-Implementation of EfficientNet for Keras\n",
    "    Reference:\n",
    "        https://arxiv.org/abs/1807.11626\n",
    "    Args:\n",
    "        input_shape: optional, if ``None`` default_input_shape is used\n",
    "            EfficientNetB0 - (224, 224, 3)\n",
    "            EfficientNetB1 - (240, 240, 3)\n",
    "            EfficientNetB2 - (260, 260, 3)\n",
    "            EfficientNetB3 - (300, 300, 3)\n",
    "            EfficientNetB4 - (380, 380, 3)\n",
    "            EfficientNetB5 - (456, 456, 3)\n",
    "            EfficientNetB6 - (528, 528, 3)\n",
    "            EfficientNetB7 - (600, 600, 3)\n",
    "        include_top: whether to include the fully-connected\n",
    "            layer at the top of the network.\n",
    "        weights: one of `None` (random initialization),\n",
    "              'imagenet' (pre-training on ImageNet).\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "        pooling: optional [None, 'avg', 'max'], if ``include_top=False``\n",
    "            add global pooling on top of the network\n",
    "            - avg: GlobalAveragePooling2D\n",
    "            - max: GlobalMaxPooling2D\n",
    "    Returns:\n",
    "        A Keras model instance.\n",
    "    \"\"\"\n",
    "    if weights not in {None, 'imagenet'}:\n",
    "        raise ValueError('Parameter `weights` should be one of [None, \"imagenet\"]')\n",
    "\n",
    "    if weights == 'imagenet' and model_name not in IMAGENET_WEIGHTS:\n",
    "        raise ValueError('There are not pretrained weights for {} model.'.format(model_name))\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` and `include_top`'\n",
    "                         ' `classes` should be 1000')\n",
    "\n",
    "    block_agrs_list, global_params, default_input_shape = get_model_params(\n",
    "        model_name, override_params={'num_classes': classes}\n",
    "    )\n",
    "\n",
    "    if input_shape is None:\n",
    "        input_shape = (default_input_shape, default_input_shape, 3)\n",
    "\n",
    "    model = EfficientNet(input_shape, block_agrs_list, global_params, include_top=include_top, pooling=pooling)\n",
    "    model._name = model_name\n",
    "\n",
    "    if weights:\n",
    "        if not include_top:\n",
    "            weights_name = model_name + '-notop'\n",
    "        else:\n",
    "            weights_name = model_name\n",
    "        weights = IMAGENET_WEIGHTS[weights_name]\n",
    "        weights_path = get_file(\n",
    "            weights['name'],\n",
    "            weights['url'],\n",
    "            cache_subdir='models',\n",
    "            md5_hash=weights['md5'],\n",
    "        )\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def EfficientNetB0(include_top=True, input_shape=None, weights=None, classes=1000, pooling=None):\n",
    "    return _get_model_by_name('efficientnet-b0', include_top=include_top, input_shape=input_shape,\n",
    "                              weights=weights, classes=classes, pooling=pooling)\n",
    "\n",
    "\n",
    "def EfficientNetB1(include_top=True, input_shape=None, weights=None, classes=1000, pooling=None):\n",
    "    return _get_model_by_name('efficientnet-b1', include_top=include_top, input_shape=input_shape,\n",
    "                              weights=weights, classes=classes, pooling=pooling)\n",
    "\n",
    "\n",
    "def EfficientNetB2(include_top=True, input_shape=None, weights=None, classes=1000, pooling=None):\n",
    "    return _get_model_by_name('efficientnet-b2', include_top=include_top, input_shape=input_shape,\n",
    "                              weights=weights, classes=classes, pooling=pooling)\n",
    "\n",
    "\n",
    "def EfficientNetB3(include_top=True, input_shape=None, weights=None, classes=1000, pooling=None):\n",
    "    return _get_model_by_name('efficientnet-b3', include_top=include_top, input_shape=input_shape,\n",
    "                              weights=weights, classes=classes, pooling=pooling)\n",
    "\n",
    "\n",
    "def EfficientNetB4(include_top=True, input_shape=None, weights=None, classes=1000, pooling=None):\n",
    "    return _get_model_by_name('efficientnet-b4', include_top=include_top, input_shape=input_shape,\n",
    "                              weights=weights, classes=classes, pooling=pooling)\n",
    "\n",
    "\n",
    "def EfficientNetB5(include_top=True, input_shape=None, weights=None, classes=1000, pooling=None):\n",
    "    return _get_model_by_name('efficientnet-b5', include_top=include_top, input_shape=input_shape,\n",
    "                              weights=weights, classes=classes, pooling=pooling)\n",
    "\n",
    "\n",
    "def EfficientNetB6(include_top=True, input_shape=None, weights=None, classes=1000, pooling=None):\n",
    "    return _get_model_by_name('efficientnet-b6', include_top=include_top, input_shape=input_shape,\n",
    "                              weights=weights, classes=classes, pooling=pooling)\n",
    "\n",
    "\n",
    "def EfficientNetB7(include_top=True, input_shape=None, weights=None, classes=1000, pooling=None):\n",
    "    return _get_model_by_name('efficientnet-b7', include_top=include_top, input_shape=input_shape,\n",
    "                              weights=weights, classes=classes, pooling=pooling)\n",
    "\n",
    "\n",
    "EfficientNetB0.__doc__ = _get_model_by_name.__doc__\n",
    "EfficientNetB1.__doc__ = _get_model_by_name.__doc__\n",
    "EfficientNetB2.__doc__ = _get_model_by_name.__doc__\n",
    "EfficientNetB3.__doc__ = _get_model_by_name.__doc__\n",
    "EfficientNetB4.__doc__ = _get_model_by_name.__doc__\n",
    "EfficientNetB5.__doc__ = _get_model_by_name.__doc__\n",
    "EfficientNetB6.__doc__ = _get_model_by_name.__doc__\n",
    "EfficientNetB7.__doc__ = _get_model_by_name.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:56.033437Z",
     "iopub.status.busy": "2021-01-25T02:31:56.027970Z",
     "iopub.status.idle": "2021-01-25T02:31:56.057667Z",
     "shell.execute_reply": "2021-01-25T02:31:56.057082Z"
    },
    "papermill": {
     "duration": 0.102698,
     "end_time": "2021-01-25T02:31:56.057805",
     "exception": false,
     "start_time": "2021-01-25T02:31:55.955107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     \"\"\"\n\u001b[1;32m   1345\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   1347\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:56.205969Z",
     "iopub.status.busy": "2021-01-25T02:31:56.205267Z",
     "iopub.status.idle": "2021-01-25T02:31:56.222360Z",
     "shell.execute_reply": "2021-01-25T02:31:56.223060Z"
    },
    "papermill": {
     "duration": 0.104865,
     "end_time": "2021-01-25T02:31:56.223249",
     "exception": false,
     "start_time": "2021-01-25T02:31:56.118384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Weights for model sequential have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-596723284980>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \"\"\"\n\u001b[1;32m   1051\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m-> 1052\u001b[0;31m                     signatures, options)\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    133\u001b[0m           'or using `save_weights`.')\n\u001b[1;32m    134\u001b[0m     hdf5_format.save_model_to_hdf5(\n\u001b[0;32m--> 135\u001b[0;31m         model, filepath, overwrite, include_optimizer)\n\u001b[0m\u001b[1;32m    136\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;31m# entities like metrics added using `add_metric` and losses added using\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m   \u001b[0;31m# `add_loss.`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_undeduplicated_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     logging.warning('Found duplicated `Variable`s in Model\\'s `weights`. '\n\u001b[1;32m     90\u001b[0m                     \u001b[0;34m'This is usually caused by `Variable`s being shared by '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mweights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    498\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m     \"\"\"\n\u001b[0;32m--> 500\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dedup_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_undeduplicated_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_undeduplicated_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    503\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_undeduplicated_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0;34m\"\"\"Returns the undeduplicated list of all layer variables/weights.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_assert_weights_created\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                        \u001b[0;34m'Weights are created when the Model is first called on '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                        \u001b[0;34m'inputs or `build()` is called with an `input_shape`.'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1562\u001b[0;31m                        self.name)\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_graph_network_add_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbolic_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Weights for model sequential have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`."
     ]
    }
   ],
   "source": [
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:56.352239Z",
     "iopub.status.busy": "2021-01-25T02:31:56.351203Z",
     "iopub.status.idle": "2021-01-25T02:31:56.382775Z",
     "shell.execute_reply": "2021-01-25T02:31:56.381899Z"
    },
    "papermill": {
     "duration": 0.098553,
     "end_time": "2021-01-25T02:31:56.382960",
     "exception": false,
     "start_time": "2021-01-25T02:31:56.284407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for layer in base_model.layers:\n",
    "    print(layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:56.514851Z",
     "iopub.status.busy": "2021-01-25T02:31:56.513830Z",
     "iopub.status.idle": "2021-01-25T02:31:56.518580Z",
     "shell.execute_reply": "2021-01-25T02:31:56.517182Z"
    },
    "papermill": {
     "duration": 0.071984,
     "end_time": "2021-01-25T02:31:56.518749",
     "exception": false,
     "start_time": "2021-01-25T02:31:56.446765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_img(images):\n",
    "    images = tf.cast(images, tf.float32)\n",
    "    images = transform_augmentation(images,\n",
    "                        rotation_range=30,\n",
    "                        shear_range=30,\n",
    "                        zoom_range=[0.8, 1.2],\n",
    "                        horizontal_flip=True, \n",
    "                        width_shift_range=0.1,\n",
    "                        height_shift_range=0.1,\n",
    "                        fill_mode='REFLECT')\n",
    "    images = color_augmentation(images,\n",
    "                     hue_range=0.1,\n",
    "                     brightness_range=0.2,\n",
    "                     saturation_range=[0.8,1.2],\n",
    "                     contrast_range=[0.8,1.2])\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:56.666773Z",
     "iopub.status.busy": "2021-01-25T02:31:56.661053Z",
     "iopub.status.idle": "2021-01-25T02:31:56.726038Z",
     "shell.execute_reply": "2021-01-25T02:31:56.725475Z"
    },
    "papermill": {
     "duration": 0.145286,
     "end_time": "2021-01-25T02:31:56.726194",
     "exception": false,
     "start_time": "2021-01-25T02:31:56.580908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "@tf.function\n",
    "def simple_augmentation(images, \n",
    "                    rescale = 1.0,\n",
    "                    width_shift_range=0.,\n",
    "                    height_shift_range=0.,\n",
    "                    horizontal_flip=False, \n",
    "                    vertical_flip=False,\n",
    "                    cval=0.0,\n",
    "                    fill_mode='constant'\n",
    "    ):\n",
    "\n",
    "    img_shape = images.shape[-3:]\n",
    "\n",
    "    if rescale != 1.0:\n",
    "        images *= rescale\n",
    "    if horizontal_flip:\n",
    "        images = tf.image.random_flip_left_right(images)\n",
    "    if vertical_flip:\n",
    "        images = tf.image.random_flip_up_down(images)\n",
    "\n",
    "    if width_shift_range != 0 or height_shift_range != 0:\n",
    "        width_shift = int(img_shape[1] * width_shift_range)\n",
    "        height_shift = int(img_shape[0] * height_shift_range)\n",
    "        pad = tf.constant([[0, 0], [height_shift, height_shift], [width_shift, width_shift], [0, 0]])\n",
    "        images = tf.pad(images, pad, mode=fill_mode, constant_values=cval)\n",
    "        images = tf.map_fn(lambda image: tf.image.random_crop(image, size=[img_shape[0], img_shape[1], img_shape[2]]), images)\n",
    "\n",
    "    return images\n",
    "@tf.function\n",
    "def color_augmentation(images,\n",
    "        rescale = 1.0,\n",
    "        brightness_range=0.0,\n",
    "        hue_range=0.0,\n",
    "        contrast_range=[1.0,1.0],\n",
    "        saturation_range=[1.0,1.0],\n",
    "        clip_range=[0.,1.]\n",
    "    ):\n",
    "    if rescale != 1.0:\n",
    "        images *= rescale\n",
    "\n",
    "    if (images.get_shape()[-1] == 1):\n",
    "        hue_range = 0.0\n",
    "        saturation_range = [1.0,1.0]\n",
    "\n",
    "    if hue_range>0.5:\n",
    "        hue_range=0.5\n",
    "\n",
    "    def color_aug(image):\n",
    "        if brightness_range != 0.0:\n",
    "            image = tf.image.random_brightness(image, brightness_range)\n",
    "        if hue_range != 0.0:\n",
    "            image = tf.image.random_hue(image, hue_range)\n",
    "        if saturation_range[0] != saturation_range[1]:\n",
    "            image = tf.image.random_saturation(image,saturation_range[0], saturation_range[1])\n",
    "        if contrast_range[0] != contrast_range[1]:\n",
    "            image = tf.image.random_contrast(image, contrast_range[0], contrast_range[1])\n",
    "        if clip_range[0] != clip_range[1]:\n",
    "            image = tf.clip_by_value(image, clip_range[0], clip_range[1])\n",
    "        return image\n",
    "\n",
    "    images = tf.map_fn(lambda image: color_aug(image), images)\n",
    "    return images\n",
    "@tf.function\n",
    "def transform_augmentation(images, \n",
    "        rescale=1.0, \n",
    "        zoom_range=[1.,1.],\n",
    "        rotation_range=0.,\n",
    "        shear_range=0.,\n",
    "        interpolation='BILINEAR',\n",
    "        width_shift_range=0., height_shift_range=0.,\n",
    "        horizontal_flip=False, vertical_flip=False,\n",
    "        fill_mode='constant',\n",
    "        cval=0.0\n",
    "        ):\n",
    "\n",
    "    if rescale!=1.0:\n",
    "        images = images*rescale\n",
    "\n",
    "    if isinstance(zoom_range,float):\n",
    "        zoom_lower = 1.0-zoom_range\n",
    "        zoom_upper = 1.0+zoom_range\n",
    "    else:\n",
    "        zoom_lower, zoom_upper = zoom_range\n",
    "\n",
    "    if shear_range>45.0:\n",
    "        shear_range = 45\n",
    "    if width_shift_range>0.5:\n",
    "        width_shift_range=0.5\n",
    "    if height_shift_range>0.5:\n",
    "        height_shift_range=0.5\n",
    "    if zoom_upper>1.5:\n",
    "        zoom_upper = 1.5\n",
    "\n",
    "    img_width = images.get_shape()[1]\n",
    "    center = img_width/2\n",
    "\n",
    "    if fill_mode.lower()=='constant':\n",
    "        fill_mode_no=0\n",
    "    else:\n",
    "        fill_mode_no=1\n",
    "\n",
    "    margin = 0\n",
    "    if fill_mode_no == 1 or cval != 0.0:\n",
    "        expand = 1.0\n",
    "        if shear_range != 0.0:\n",
    "            expand += math.tan(shear_range*3.141519/180)\n",
    "        if rotation_range != 0.0:\n",
    "            expand *= math.sqrt(2)\n",
    "        expand *= zoom_upper\n",
    "        margin += int(center*expand - center)\n",
    "        shift_max = int(max((width_shift_range*img_width, height_shift_range*img_width)))\n",
    "        margin+=shift_max\n",
    "        if margin >= img_width:\n",
    "            margin=img_width-1\n",
    "\n",
    "        center = center+float(margin)\n",
    "    def transform(image):\n",
    "        angle = tf.random.uniform(shape=[], minval=-rotation_range, maxval=rotation_range)*3.141519/180\n",
    "        if horizontal_flip:\n",
    "            mirror_x = tf.cast(tf.random.uniform(shape=[], minval=0, maxval=2, dtype=tf.dtypes.int32)*2-1, tf.float32)\n",
    "        else:\n",
    "            mirror_x = 1.0\n",
    "        if vertical_flip:\n",
    "            mirror_y = tf.cast(tf.random.uniform(shape=[], minval=0, maxval=2, dtype=tf.dtypes.int32)*2-1, tf.float32)\n",
    "        else:\n",
    "            mirror_y = 1.0\n",
    "        zoom_x = tf.random.uniform(shape=[], minval=zoom_lower, maxval=zoom_upper)\n",
    "        zoom_y = tf.random.uniform(shape=[], minval=zoom_lower, maxval=zoom_upper)\n",
    "        width_shift = tf.random.uniform(shape=[], minval=-width_shift_range, maxval=width_shift_range)*img_width\n",
    "        height_shift = tf.random.uniform(shape=[], minval=-height_shift_range, maxval=height_shift_range)*img_width\n",
    "        shear_val = tf.random.uniform(shape=[], minval=-shear_range, maxval=shear_range)*3.141519/180\n",
    "\n",
    "        if fill_mode_no == 1:\n",
    "            image = tf.pad(image, tf.constant([[margin, margin], [margin, margin], [0, 0]]), mode=\"REFLECT\")\n",
    "        elif  cval != 0.0:\n",
    "            image = tf.pad(image, tf.constant([[margin, margin], [margin, margin], [0, 0]]), mode=\"CONSTANT\", constant_values=cval)\n",
    "\n",
    "        sinval = tf.sin(angle)\n",
    "        cosval = tf.cos(angle)\n",
    "        center_mat = [1.0, 0.0, center, 0.0, 1.0, center, 0.0, 0.0]\n",
    "        shear_mat=[1.0, 0.0, 0.0, tf.tan(shear_val), 1.0, 0.0, 0.0, 0.0]\n",
    "        rotate_mat = [cosval, -sinval, 0.0, sinval, cosval, 0.0, 0.0, 0.0]\n",
    "        zoom_mat = [zoom_x*mirror_x, 0.0, 0.0, 0.0, zoom_y*mirror_y, 0.0, 0.0, 0.0]\n",
    "        center_mat_inv = [1.0, 0.0, width_shift-center, 0.0, 1.0, height_shift-center, 0.0, 0.0]\n",
    "\n",
    "        matrix = [center_mat, shear_mat, rotate_mat, zoom_mat, center_mat_inv]\n",
    "        composed_matrix = tfa.image.transform_ops.compose_transforms(matrix)\n",
    "        image = tfa.image.transform(image, composed_matrix, interpolation=interpolation)\n",
    "\n",
    "        if fill_mode_no == 1 or cval != 0.0:\n",
    "            image = tf.image.resize_with_crop_or_pad(image, img_width, img_width)\n",
    "\n",
    "        return image\n",
    "\n",
    "    images = tf.map_fn(lambda image: transform(image), images)\n",
    "\n",
    "    return images\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "from scipy import linalg\n",
    "class ImageStandardization():\n",
    "    def __init__(self, x, \n",
    "            rescale = 1.0,\n",
    "            samplewise_center=False, \n",
    "            samplewise_std_normalization=False, \n",
    "            featurewise_center=False, \n",
    "            featurewise_std_normalization=False, \n",
    "            zca_whitening=False,\n",
    "            zca_epsilon=1e-6\n",
    "        ):\n",
    "        self.samplewise_center = samplewise_center\n",
    "        self.samplewise_std_normalization = samplewise_std_normalization\n",
    "        self.rescale = rescale\n",
    "\n",
    "        if zca_whitening:\n",
    "            featurewise_center = True\n",
    "            featurewise_std_normalization = False\n",
    "        if featurewise_std_normalization:\n",
    "            featurewise_center = True\n",
    "        if self.samplewise_std_normalization:\n",
    "            self.samplewise_center = True\n",
    "\n",
    "        x = np.array(x, dtype=np.float32)\n",
    "        if self.rescale != 1.0:\n",
    "            x *= self.rescale\n",
    "\n",
    "        broadcast_shape = [1, 1, x.shape[3]]\n",
    "        if featurewise_center:\n",
    "            self.mean = np.mean(x, axis=(0, 1, 2))\n",
    "            self.mean = np.reshape(self.mean, broadcast_shape)\n",
    "            x -= self.mean\n",
    "        else:\n",
    "            self.mean = None\n",
    "\n",
    "        if featurewise_std_normalization:\n",
    "            self.std = np.std(x, axis=(0, 1, 2))\n",
    "            self.std = np.reshape(self.std, broadcast_shape)\n",
    "            x /= (self.std + 1e-6)\n",
    "        else:\n",
    "            self.std = None\n",
    "\n",
    "        if zca_whitening:\n",
    "            flat_x = np.reshape(\n",
    "                x, (x.shape[0], x.shape[1] * x.shape[2] * x.shape[3]))\n",
    "            sigma = np.dot(flat_x.T, flat_x) / flat_x.shape[0]\n",
    "            u, s, _ = linalg.svd(sigma)\n",
    "            s_inv = 1. / np.sqrt(s[np.newaxis] + zca_epsilon)\n",
    "            self.principal_components = (u * s_inv).dot(u.T)\n",
    "            self.flatshape = (-1, np.prod(x.shape[-3:]))\n",
    "            self.shape = (-1, x.shape[1], x.shape[2], x.shape[3])\n",
    "        else:\n",
    "            self.principal_components = None\n",
    "\n",
    "    @tf.function\n",
    "    def standardize(self, x):\n",
    "        if self.rescale != 1.0:\n",
    "            x *= self.rescale\n",
    "        if self.samplewise_center:\n",
    "            def center(image):\n",
    "                mean = tf.math.reduce_mean(image, axis=None, keepdims=True)\n",
    "                image -= mean\n",
    "                return image\n",
    "            x = tf.map_fn(lambda image: center(image), x)\n",
    "        if self.samplewise_std_normalization:\n",
    "            def normalize(image):\n",
    "                std = tf.math.reduce_std(image, axis=None, keepdims=True)\n",
    "                image *= 1./(std + 1e-6)\n",
    "                return image\n",
    "            x = tf.map_fn(lambda image: normalize(image), x)\n",
    "\n",
    "        if self.mean is not None:\n",
    "            x -= self.mean\n",
    "\n",
    "        if self.std is not None:\n",
    "            x /= (self.std + 1e-6)\n",
    "\n",
    "        if self.principal_components is not None:\n",
    "            flatx = tf.reshape(x, self.flatshape)\n",
    "            whitex = tf.tensordot(flatx, tf.convert_to_tensor(self.principal_components), axes=1)\n",
    "            x = tf.reshape(whitex, self.shape)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:56.855072Z",
     "iopub.status.busy": "2021-01-25T02:31:56.854339Z",
     "iopub.status.idle": "2021-01-25T02:31:56.857775Z",
     "shell.execute_reply": "2021-01-25T02:31:56.857119Z"
    },
    "papermill": {
     "duration": 0.070962,
     "end_time": "2021-01-25T02:31:56.857910",
     "exception": false,
     "start_time": "2021-01-25T02:31:56.786948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Reshape\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import UpSampling2D, Convolution2D\n",
    "\n",
    "def generator_model():\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:56.994109Z",
     "iopub.status.busy": "2021-01-25T02:31:56.993444Z",
     "iopub.status.idle": "2021-01-25T02:31:56.996949Z",
     "shell.execute_reply": "2021-01-25T02:31:56.996262Z"
    },
    "papermill": {
     "duration": 0.075254,
     "end_time": "2021-01-25T02:31:56.997066",
     "exception": false,
     "start_time": "2021-01-25T02:31:56.921812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Flatten, Dropout\n",
    "\n",
    "def discriminator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(64, 5, 5,\n",
    "                            subsample=(2, 2),\n",
    "                            border_mode='same',\n",
    "                            input_shape=(1, 28, 28)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Convolution2D(128, 5, 5, subsample=(2, 2)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:57.122485Z",
     "iopub.status.busy": "2021-01-25T02:31:57.121757Z",
     "iopub.status.idle": "2021-01-25T02:31:57.132750Z",
     "shell.execute_reply": "2021-01-25T02:31:57.131888Z"
    },
    "papermill": {
     "duration": 0.073764,
     "end_time": "2021-01-25T02:31:57.132898",
     "exception": false,
     "start_time": "2021-01-25T02:31:57.059134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def combine_images(generated_images):\n",
    "    total = generated_images.shape[0]\n",
    "    cols = int(math.sqrt(total))\n",
    "    rows = math.ceil(float(total)/cols)\n",
    "    width, height = generated_images.shape[2:]\n",
    "    combined_image = np.zeros((height*rows, width*cols),\n",
    "                              dtype=generated_images.dtype)\n",
    "\n",
    "    for index, image in enumerate(generated_images):\n",
    "        i = int(index/cols)\n",
    "        j = index % cols\n",
    "        combined_image[width*i:width*(i+1), height*j:height*(j+1)] = image[0, :, :]\n",
    "    return combined_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:57.282200Z",
     "iopub.status.busy": "2021-01-25T02:31:57.280867Z",
     "iopub.status.idle": "2021-01-25T02:31:57.284303Z",
     "shell.execute_reply": "2021-01-25T02:31:57.283763Z"
    },
    "papermill": {
     "duration": 0.091243,
     "end_time": "2021-01-25T02:31:57.284425",
     "exception": false,
     "start_time": "2021-01-25T02:31:57.193182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from PIL import Image\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCH = 20\n",
    "GENERATED_IMAGE_PATH = 'generated_images/' # 生成画像の保存先\n",
    "def get_training_dataset2():\n",
    "    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)  \n",
    "    dataset = dataset.map(data_augment, num_parallel_calls=AUTOTUNE)  \n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset\n",
    "def train():\n",
    "    data=get_training_dataset2()\n",
    "    #X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "    #X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "    discriminator = discriminator_model()\n",
    "    d_opt = Adam(lr=1e-5, beta_1=0.1)\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=d_opt)\n",
    "\n",
    "    # generator+discriminator （discriminator部分の重みは固定）\n",
    "    discriminator.trainable = False\n",
    "    generator = generator_model()\n",
    "    dcgan = Sequential([generator, discriminator])\n",
    "    g_opt = Adam(lr=2e-4, beta_1=0.5)\n",
    "    dcgan.compile(loss='binary_crossentropy', optimizer=g_opt)\n",
    "\n",
    "    num_batches = int(X_train.shape[0] / BATCH_SIZE)\n",
    "    print('Number of batches:', num_batches)\n",
    "    for epoch in range(NUM_EPOCH):\n",
    "\n",
    "        for index in range(num_batches):\n",
    "            noise = np.array([np.random.uniform(-1, 1, 100) for _ in range(BATCH_SIZE)])\n",
    "            image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            generated_images = generator.predict(noise, verbose=0)\n",
    "\n",
    "            # 生成画像を出力\n",
    "            if index % 500 == 0:\n",
    "                image = combine_images(generated_images)\n",
    "                image = image*127.5 + 127.5\n",
    "                if not os.path.exists(GENERATED_IMAGE_PATH):\n",
    "                    os.mkdir(GENERATED_IMAGE_PATH)\n",
    "                Image.fromarray(image.astype(np.uint8))\\\n",
    "                    .save(GENERATED_IMAGE_PATH+\"%04d_%04d.png\" % (epoch, index))\n",
    "\n",
    "            # discriminatorを更新\n",
    "            X = np.concatenate((image_batch, generated_images))\n",
    "            y = [1]*BATCH_SIZE + [0]*BATCH_SIZE\n",
    "            d_loss = discriminator.train_on_batch(X, y)\n",
    "\n",
    "            # generatorを更新\n",
    "            noise = np.array([np.random.uniform(-1, 1, 100) for _ in range(BATCH_SIZE)])\n",
    "            g_loss = dcgan.train_on_batch(noise, [1]*BATCH_SIZE)\n",
    "            print(\"epoch: %d, batch: %d, g_loss: %f, d_loss: %f\" % (epoch, index, g_loss, d_loss))\n",
    "\n",
    "        generator.save_weights('generator.h5')\n",
    "        discriminator.save_weights('discriminator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:57.428501Z",
     "iopub.status.busy": "2021-01-25T02:31:57.427732Z",
     "iopub.status.idle": "2021-01-25T02:31:57.431020Z",
     "shell.execute_reply": "2021-01-25T02:31:57.431557Z"
    },
    "papermill": {
     "duration": 0.08703,
     "end_time": "2021-01-25T02:31:57.431702",
     "exception": false,
     "start_time": "2021-01-25T02:31:57.344672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-34-329ffc7a42fd>, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-34-329ffc7a42fd>\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    discriminator = tf.keras.Sequential([\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():     \n",
    "    generator = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(input_dim=2000, output_dim=512*512),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activatio('relu'),\n",
    "        tf.keras.layers.Dense(128*32*32)\n",
    "        \n",
    "    ])\n",
    "    generator.add(BatchNormalization())\n",
    "    generator.add(Activation('relu'))\n",
    "    generator.add(Reshape((128, 32, 32), input_shape=(128*32*32,)))\n",
    "    generator.add(UpSampling2D((2, 2)))\n",
    "    generator.add(Convolution2D(64, 5, 5, border_mode='same'))\n",
    "    for i in range(3):\n",
    "        generator.add(BatchNormalization())\n",
    "        generator.add(Activation('relu'))\n",
    "        #generator.add(Reshape((128, 7, 7), input_shape=(128*32*32,)))\n",
    "        generator.add(UpSampling2D((2, 2)))\n",
    "        generator.add(Convolution2D(64, 5, 5, border_mode='same'))\n",
    "    generator.add(Activation('tanh')\n",
    "    discriminator = tf.keras.Sequential([\n",
    "        Convolution2D(64, 5, 5,\n",
    "                            subsample=(2, 2),\n",
    "                            border_mode='same',\n",
    "                            input_shape=(1, 512, 512)),\n",
    "        tf.keras.layers.LeakyReLU(0.2),\n",
    "        tf.keras.layers.Convolution2D(128, 5, 5, subsample=(2, 2)),\n",
    "        tf.keras.layers.LeakyReLU(0.2),\n",
    "        tf.keras.layers.Convolution2D(128, 5, 5, subsample=(2, 2)),\n",
    "        tf.keras.layers.LeakyReLU(0.2),\n",
    "        tf.keras.layers.Convolution2D(128, 5, 5, subsample=(2, 2)),\n",
    "        tf.keras.layers.LeakyReLU(0.2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(256),\n",
    "        tf.keras.layers.LeakyReLU(0.2),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1),\n",
    "        \n",
    "    ])   \n",
    "    discriminator.trainable = False\n",
    "    #generator = generator_model()\n",
    "    dcgan = tf.keras.Sequential([generator, discriminator])              \n",
    "    #d_opt = Adam(lr=1e-5, beta_1=0.1)\n",
    "    #discriminator.compile(loss='binary_crossentropy', optimizer=d_opt)\n",
    "# load data\n",
    "EPOCHS = 5\n",
    "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n",
    "VALID_STEPS = NUM_VALIDATION_IMAGES // BATCH_SIZE\n",
    "history = model.fit(train_dataset, \n",
    "                    steps_per_epoch=STEPS_PER_EPOCH, \n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=valid_dataset,\n",
    "                    validation_steps=VALID_STEPS,\n",
    "                    callbacks=callbacks_list\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:57.564896Z",
     "iopub.status.busy": "2021-01-25T02:31:57.559015Z",
     "iopub.status.idle": "2021-01-25T02:31:57.587280Z",
     "shell.execute_reply": "2021-01-25T02:31:57.586679Z"
    },
    "papermill": {
     "duration": 0.094654,
     "end_time": "2021-01-25T02:31:57.587417",
     "exception": false,
     "start_time": "2021-01-25T02:31:57.492763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _leaky_relu(x):\n",
    "  return tf.nn.leaky_relu(x, alpha=0.2)\n",
    "\n",
    "\n",
    "def _batch_norm(x, is_training, name):\n",
    "  return tf.layers.batch_normalization(\n",
    "      x, momentum=0.9, epsilon=1e-5, training=is_training, name=name)\n",
    "\n",
    "\n",
    "def _dense(x, channels, name):\n",
    "  return tf.layers.dense(\n",
    "      x, channels,\n",
    "      kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "      name=name)\n",
    "\n",
    "\n",
    "def _conv2d(x, filters, kernel_size, stride, name):\n",
    "  return tf.layers.conv2d(\n",
    "      x, filters, [kernel_size, kernel_size],\n",
    "      strides=[stride, stride], padding='same',\n",
    "      kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "      name=name)\n",
    "\n",
    "\n",
    "def _deconv2d(x, filters, kernel_size, stride, name):\n",
    "  return tf.layers.conv2d_transpose(\n",
    "      x, filters, [kernel_size, kernel_size],\n",
    "      strides=[stride, stride], padding='same',\n",
    "      kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "      name=name)\n",
    "\n",
    "\n",
    "def discriminator(images, unused_conditioning, is_training=True,\n",
    "                  scope='Discriminator'):\n",
    "  \"\"\"Discriminator for CIFAR images.\n",
    "\n",
    "  Args:\n",
    "    images: A Tensor of shape [batch size, width, height, channels], that can be\n",
    "      either real or generated. It is the discriminator's goal to distinguish\n",
    "      between the two.\n",
    "    unused_conditioning: The TFGAN API can help with conditional GANs, which\n",
    "      would require extra `condition` information to both the generator and the\n",
    "      discriminator. Since this example is not conditional, we do not use this\n",
    "      argument.\n",
    "    is_training: If `True`, batch norm uses batch statistics. If `False`, batch\n",
    "      norm uses the exponential moving average collected from population\n",
    "      statistics.\n",
    "    scope: A variable scope or string for the discriminator.\n",
    "\n",
    "  Returns:\n",
    "    A 1D Tensor of shape [batch size] representing the confidence that the\n",
    "    images are real. The output can lie in [-inf, inf], with positive values\n",
    "    indicating high confidence that the images are real.\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
    "    x = _conv2d(images, 64, 5, 2, name='d_conv1')\n",
    "    x = _leaky_relu(x)\n",
    "\n",
    "    x = _conv2d(x, 128, 5, 2, name='d_conv2')\n",
    "    x = _leaky_relu(_batch_norm(x, is_training, name='d_bn2'))\n",
    "\n",
    "    x = _conv2d(x, 256, 5, 2, name='d_conv3')\n",
    "    x = _leaky_relu(_batch_norm(x, is_training, name='d_bn3'))\n",
    "\n",
    "    x = tf.reshape(x, [-1, 4 * 4 * 256])\n",
    "\n",
    "    x = _dense(x, 1, name='d_fc_4')\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def generator(noise, is_training=True, scope='Generator'):\n",
    "  \"\"\"Generator to produce CIFAR images.\n",
    "\n",
    "  Args:\n",
    "    noise: A 2D Tensor of shape [batch size, noise dim]. Since this example\n",
    "      does not use conditioning, this Tensor represents a noise vector of some\n",
    "      kind that will be reshaped by the generator into CIFAR examples.\n",
    "    is_training: If `True`, batch norm uses batch statistics. If `False`, batch\n",
    "      norm uses the exponential moving average collected from population\n",
    "      statistics.\n",
    "    scope: A variable scope or string for the generator.\n",
    "\n",
    "  Returns:\n",
    "    A single Tensor with a batch of generated CIFAR images.\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
    "    net = _dense(noise, 4096, name='g_fc1')\n",
    "    net = tf.nn.relu(_batch_norm(net, is_training, name='g_bn1'))\n",
    "\n",
    "    net = tf.reshape(net, [-1, 4, 4, 256])\n",
    "\n",
    "    net = _deconv2d(net, 128, 5, 2, name='g_dconv2')\n",
    "    net = tf.nn.relu(_batch_norm(net, is_training, name='g_bn2'))\n",
    "\n",
    "    net = _deconv2d(net, 64, 4, 2, name='g_dconv3')\n",
    "    net = tf.nn.relu(_batch_norm(net, is_training, name='g_bn3'))\n",
    "\n",
    "    net = _deconv2d(net, 3, 4, 2, name='g_dconv4')\n",
    "    net = tf.tanh(net)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:57.722602Z",
     "iopub.status.busy": "2021-01-25T02:31:57.720752Z",
     "iopub.status.idle": "2021-01-25T02:31:57.830330Z",
     "shell.execute_reply": "2021-01-25T02:31:57.831226Z"
    },
    "papermill": {
     "duration": 0.182582,
     "end_time": "2021-01-25T02:31:57.831446",
     "exception": false,
     "start_time": "2021-01-25T02:31:57.648864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_gan'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-925c9349523f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_gan\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfgan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_eager_execution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_gan'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tensorflow_gan as tfgan\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "noise_dims = 1024 #@param\n",
    "generator_lr = 0.0002  #@param\n",
    "discriminator_lr = 0.0002  #@param\n",
    "train_batch_size = 1024  #@param\n",
    "\n",
    "config = tf.estimator.tpu.RunConfig(\n",
    "    model_dir=model_dir,\n",
    "    master=tpu_address,\n",
    "    tpu_config=tf.estimator.tpu.TPUConfig(iterations_per_loop=images_per_batch))\n",
    "est = tfgan.estimator.TPUGANEstimator(\n",
    "    generator_fn=generator,\n",
    "    discriminator_fn=discriminator,\n",
    "    generator_loss_fn=tfgan.losses.modified_generator_loss,\n",
    "    discriminator_loss_fn=tfgan.losses.modified_discriminator_loss,\n",
    "    generator_optimizer=tf.train.AdamOptimizer(generator_lr, 0.5),\n",
    "    discriminator_optimizer=tf.train.AdamOptimizer(discriminator_lr, 0.5),\n",
    "    joint_train=True,  # train G and D jointly instead of sequentially.\n",
    "    train_batch_size=train_batch_size,\n",
    "    predict_batch_size=images_per_batch,\n",
    "    use_tpu=True,\n",
    "    params={'noise_dims': noise_dims},\n",
    "    config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T02:31:58.053884Z",
     "iopub.status.busy": "2021-01-25T02:31:58.052700Z",
     "iopub.status.idle": "2021-01-25T02:31:58.058729Z",
     "shell.execute_reply": "2021-01-25T02:31:58.058129Z"
    },
    "papermill": {
     "duration": 0.131082,
     "end_time": "2021-01-25T02:31:58.058853",
     "exception": false,
     "start_time": "2021-01-25T02:31:57.927771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'init_global_real_logits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-c77e7dc9fc5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0minit_global_real_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Initialized classifier logits for real data.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mclassifier_score_real_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_real_data_classifier_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'init_global_real_logits' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "max_steps = 50000 #@param\n",
    "steps_per_eval = 5000 #@param\n",
    "\n",
    "cur_step = 0\n",
    "start_time = time.time()\n",
    "cscores, fids, steps = [], [], []\n",
    "init_global_real_logits()\n",
    "print('Initialized classifier logits for real data.')\n",
    "classifier_score_real_data = calculate_real_data_classifier_score()\n",
    "print('Calculated classifier score for real data.')\n",
    "while cur_step < max_steps:\n",
    "  # Train for a fixed number of steps.\n",
    "  start_step = cur_step\n",
    "  step_to_stop_at = min(cur_step + steps_per_eval, max_steps)\n",
    "  start = time.time()\n",
    "  est.train(input_fn, max_steps=step_to_stop_at)\n",
    "  end = time.time()\n",
    "  cur_step = step_to_stop_at\n",
    "  \n",
    "  # Print some performance statistics.\n",
    "  steps_taken = step_to_stop_at - start_step\n",
    "  time_taken = end - start\n",
    "  steps_per_sec = steps_taken / time_taken\n",
    "  min_since_start = (time.time() - start_time) / 60.0\n",
    "  print(\"Current step: %i, %.4f steps / sec, time since start: %.1f min\" % (\n",
    "      cur_step, steps_per_sec, min_since_start))\n",
    "  \n",
    "  # Calculate some evaluation metrics.\n",
    "  eval_start_time = time.time()\n",
    "  cscore, fid = get_inception_score_and_fid(est)\n",
    "  eval_time = (time.time() - eval_start_time)\n",
    "  cscores.append(cscore)\n",
    "  fids.append(fid)\n",
    "  steps.append(cur_step)\n",
    "  print(\"Classifier score: %.2f / %.2f, FID: %.1f, \"\n",
    "        \"time to calculate eval: %.2f sec\" % (\n",
    "            cscore, classifier_score_real_data, fid, eval_time))\n",
    "  \n",
    "  # Generate and show some predictions.\n",
    "  predictions = np.array(\n",
    "      [x['generated_data'] for x in est.predict(noise_input_fn)])[:80]\n",
    "  image_grid = tfgan.eval.python_image_grid(predictions, grid_shape=(8, 10))\n",
    "  _show_image_grid(image_grid)\n",
    "\n",
    "# Plot the metrics vs step.\n",
    "plt.title('Frechet distance per step')\n",
    "plt.plot(steps, fids)\n",
    "plt.figure()\n",
    "plt.title('Classifier Score per step')\n",
    "plt.plot(steps, cscores)\n",
    "plt.plot(steps, [classifier_score_real_data] * len(steps))\n",
    "plt.figure()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 138.97178,
   "end_time": "2021-01-25T02:31:58.238466",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-25T02:29:39.266686",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
